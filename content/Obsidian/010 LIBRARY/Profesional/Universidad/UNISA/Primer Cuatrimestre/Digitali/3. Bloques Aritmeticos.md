



# 3. Bloques Aritméticos
## Introducción

- **Sommatori**
	- Quale sono le sommatori di base?
		- Cosa hanno di diverso?
	- Quale sono le diverse tipi di sommatori di N bits?
	- Come funziona il sumattori Ripple Carry Adders?
		- Quale sono le suoi vantaggi e svantaggi?
	- Cosa è il block generate e block propagate?
	- Come funziona il Carry Skip Adder/Carry Bypass Adder?
		- Quale sono le suoi vantaggi e svantaggi?
	- Come funziona il Carry Look Ahead Adder?
		- Quale sono le suoi vantaggi e svantaggi?
	- Come funziona el Bren-Kung Adder?
		- Quale sono le suoi vantaggi e svantaggi?
		- Cosa ha di diverso tra questo sommatore e il Carry look ahead adder?
	- Come funziona il Carry select?
		- Quale sono le suoi caratteristica?
	- Come funziona il Sommatore condizionale?
		- Cosa ha di diverso con il Carry select?
	- Cosa è i compressori e i sommatori carry save?
		- Cosa è la notazione dei punti?
		- Come funzionano i compressori di ordine superiore?
		- Quale sono gli usi di questi compressori?
	- Come si puoi applicare la sottrazione con il circuito della somma?
	- Come si potessi implementare un sommatore con le menore quantita di risorse?
- **Multiplicatori**
	- Come funziona un multiplicattore parallelo?
		- Quale sono le etapa principale?
	- Quale sone i metodi per fare la generazione di prodotti parziali?
		- Come funziona il metodo ANDing?
		- Come funziona il metodo Booth?
	- Quale sono i metodi per fare la riduzione dei prodotti parziali?
		- Come funziona la riduzione Carry Save?
		- Come funziona la riduzione Dual Save?
		- Come funziona la riduzione Wallace?
		- Come funziona la riduczione Dadda?
	- **Multiplicadores signado**
		- Quale sono i metodi per fare una multiplicazione signada?
			- Come funziona il vettore de correzione?
			- Come funziona il digito cannonico ocn segno?
			- Come funziona la aritmetica distribuida in memoria ROM?
			- Quando debo utiizare ognuno?
	- **Multiplicatore per costanti**
		- Perche è necessario un metodo per fare questo?
		- Quale è il metodo più utilizzato?
- **Altri cose**
	- Quale operazione si puoi applicare con il barrel shifter?
		- Quale è il vantaggi di questo?
	- Come si puoi megliorare un filtro FIR con questi metodi che abbiamo visto oggi




# Proc. Emb. e Unità aritmetiche in FPGAs

## Introduzione
- Le FPGAs sono emerse come dispositivi che permettono di sviluppare applicazioni di elaborazione dei segnali ad alte prestazioni.
  - Hanno superato la tradizionale tecnologia dei processori di segnale DSP.
  - Attualmente, le FPGAs includono processori incorporati, interfacce standard e blocchi di elaborazione dei segnali costituiti da moltiplicatori, sommatori, registri e multiplexer.

## Strumenti per la progettazione di unità aritmetiche in FPGA
- L'utente può configurare diverse opzioni di sintesi per la progettazione. Gli strumenti dispongono di blocchi di base di costruzione.
  - In caso di operazioni di ordine superiore, lo strumento farà copie multiple e combinazioni di questi blocchi di base per ottenere la funzionalità desiderata.
  - Ad esempio, se si progetta un moltiplicatore di 32 bit per 32 bit, lo strumento inserirà quattro moltiplicatori di 18 bit per 18 bit per soddisfare il design richiesto.
![[Pasted image 20240218182506.png]]

- L'utente può anche istanziare esplicitamente questi blocchi di base se il design lo richiedesse.
- Il produttore fornisce nello strumento di progettazione modelli che contengono questi blocchi per essere utilizzati dal progettista.
- Questi blocchi di base sono integrati nel dispositivo.
- Nel caso in cui l'FPGA esaurisca le risorse integrate, costruirà i blocchi utilizzando componenti di logica generica contenuti nel dispositivo FPGA.
- Questi blocchi generati funzionano con minore efficienza rispetto ai blocchi integrati.
- Queste risorse integrate hanno portato a un grande salto nelle prestazioni delle implementazioni.

### Confronto delle risorse utilizzate con e senza DSP
- È stato implementato un filtro IIR di secondo ordine in una Spartan 3 e una Virtex 4.
  - La prima non dispone di DSP ma ha blocchi di moltiplicatori integrati di 18 bit.
  - La Virtex dispone di DSP 48.
![[Pasted image 20240218183226.png|400]]![[Pasted image 20240218183235.png|400]]![[Pasted image 20240218183228.png|300]]

# Sommatori

## Introduzione
- I blocchi aritmetici di un sistema sono essenziali, principalmente i sommatori, poiché vengono utilizzati in addizione, sottrazione, moltiplicazione e divisione.
- Per una somma di 2 operandi di N bit, la loro rappresentazione in uscita sarà di N+1 bit.
- *Perché ci sono così tanti tipi di sommatori?* Perché si cerca di manipolare nel miglior modo possibile il carry.

### Sommatori di base 
#### Half Adders
Circuito combinazionale utilizzato per sommare 2 bit $a_i$ e $b_i$, senza un carry in ingresso: $$s_i = a_i \bigoplus b_i$$
$$c_i = a_i b_i$$
#### Full adders
Un sommatore di 3 bit, chiamato anche compressore 3 a 2: $$s_i = a_i \bigoplus b_i \bigoplus c_i$$
$$c_{i+1} = (a_i \bigoplus b_i) c_i \bigoplus a_i b_i$$- Queste strutture vengono implementate in modo diverso a seconda dello strumento e dell'hardware.
  - Nelle FPGA si possono usare LUT, per esempio.
##### Esempi di implementazione full adders
![[Pasted image 20231108112100.png|400]]



### Diversi tipi di sommatori di N bit 
- **Ripple-Carry (RCA):** Sono i più lenti della famiglia dei sommatori, implementano il modo tradizionale di sommare 2 numeri, si aspetta che venga generato il carry dopo la somma. Il loro lato positivo è la semplicità, che permette un numero minore di porte.
- **Look-ahead-adder:** Sommatori veloci, con propagazione del carry più rapida ed efficiente, consentendo che i carry vengano generati simultaneamente tramite una logica di generazione del carry. Questo permette di eseguire la somma in parallelo senza dover attendere la propagazione del carry.
- **Carry Select Adder (CSA):** Divide la somma in K gruppi, per guadagnare velocità la logica è replicata e per ogni gruppo la somma assume un carry in ingresso (0 o 1). Quando si ottiene un carry, questo seleziona il blocco successivo in base al suo valore e così via.
- **Conditional Sum Adder:** Come un CSA con il massimo numero possibile di livelli. L'operazione di selezione del carry nel primo livello è eseguita da gruppi di 1 bit. Nel livello successivo, due gruppi adiacenti si fondono per dare il risultato di un'operazione di selezione del carry di 2 bit. Questa fusione è ripetuta fino a quando gli ultimi due gruppi si fondono per generare la somma finale e il carry in uscita. È il più veloce della famiglia.



### Ripple carry adders (RCA) 
- Considerato il sommatore più lento.
  - Sono i blocchi di somma di base in un FPGA (sono i più ideali) poiché possono utilizzare la catena del carry.
  - Usano un'area minima e una struttura regolare.
  - Non devono essere usati in ASIC se si cerca velocità.
- Se si sommano 2 operandi di N bit, sono necessari N full adders.
![[Pasted image 20231108112410.png|400]]
- Ritardo: $T_{RCA} = (N-1)T_{FA} + T_M$
- Dove TRCA è il ritardo del RCA, TFA è il ritardo del FA e TM è la logica di generazione del carry.
  - Se la nostra logica di carry è un altro FA, il ritardo è N.TFA.


#### Codice di implementazione
![[Pasted image 20240218194101.png]]
#### Implementazione in FPGA
![[Pasted image 20240218194629.png]]
- Dobbiamo assicurarci che venga utilizzata la catena del carry quando usiamo questa architettura.

## Sommatori Veloci


### Block Generate e Block Propagate 
- Per la somma, non è sempre necessario calcolare il carry.
![[Pasted image 20231108121439.png]]
Quindi → $Cout = A \cdot B + (A \bigoplus B) \cdot Cin$
- Quando applichiamo questo per diversi bit, otteniamo: $$Ci+1 = G_i + P_iG_{i-1} + P_iP_{i-1}G_{i-2} + ... + P_iP_{i-1}...P_0C_{in}$$- Questo può essere scritto come: $$C_{i+1} = BGi + BPi \cdot C_{in}$$- Dove il **BG è il block generate (AND) e il BP è il block propagate (XOR)**, quest'ultimo è uguale al prodotto di P dell'ultimo termine della sommatoria.
- Questo indica che se $a_i = b_i = 1$, $c_{i+1}$ è generato, ma se solo uno dei due è 1, allora è propagato.




### Carry Skip Adder/Carry Bypass Adder 
- In un carry skip adder di N bit, questi bit sono divisi in gruppi di k bit.
- Il sommatore propaga tutti i carry simultaneamente attraverso questi gruppi.
- Se ogni gruppo genera carry, lo passa al gruppo successivo.
- Se il gruppo non genera carry a causa della distribuzione dei bit nel blocco, allora trasferisce semplicemente il carry dal gruppo precedente al gruppo successivo (bypass del carry).
- Questo bypass del carry è gestito da Pi.
- Calcoliamo Pi e questo in un multiplexer decide se abbiamo bisogno del carry generato o possiamo usare quello propagato.
![[Pasted image 20240218202443.png]] ![[Pasted image 20231108124143.png]]
- Un vantaggio di questa struttura è che se BP dell'ultimo blocco è 0, possiamo prendere il carry generato localmente senza dover aspettare quello propagato.
##### Analisi temporale a seconda del valore di Pi
![[Pasted image 20231108124356.png]]
- La migliore condizione è 1,1,1.
- La peggiore è 1,1,0.
- Analizzeremo la peggiore, che genericamente è $$tp = mt_{a} + pt_{mux}$$- L'espressione è molto simile a quella calcolata nel Carry Select Adder, il che ci lascia come risultato $$p = \sqrt{\frac{Nt_{a}}{t_{mux}}}$$$$tp = 2\sqrt{Nt_{a}t_{mux}} \approx \sqrt{N}$$
- Anche se è maggiore del **Carry Select Adder**, non dimentichiamo che stiamo confrontando il peggiore caso e questo è molto più compatto del CSA.
#### Sistema più ottimizzato
- Per realizzare un blocco di propagazione di 4 bit, abbiamo bisogno di 4 XOR e 4 AND.
- Per trovare il blocco più ottimizzato con questa architettura, dobbiamo:
  - Eguagliare i ritardi del carry sia nella generazione che nella propagazione per ogni blocco.
  - Eguagliare i ritardi nelle operazioni di somma in tutti i blocchi, in modo che i bit di somma siano generati idealmente simultaneamente in tutti i blocchi.
- Quando analizziamo il ritardo del BP in un blocco di i bit, ci rendiamo conto che il ritardo cresce linearmente con i. $$L(i) = (i-1)\frac{t_{mux}}{t_{a}} + L(0)$$
- Quando analizziamo il ritardo della somma, ci rendiamo conto che è la stessa espressione, solo che con una relazione decrescente. $$L(i) = (p-i)\frac{t_{mux}}{t_{a}} + L(p)$$
- La soluzione ottimale è blocchi centrali più lunghi e blocchi estremi più corti.
![[Pasted image 20231108130345.png]]



### Carry Look-Ahead Adder (CLA) 
- Facendo un'analisi più approfondita della generazione del carry (**Block Generate e Block Propagate**), si può arrivare al fatto che non deve dipendere dai carry precedenti.
- In un carry look-ahead adder (CLA), il carry dei bit di tutte le posizioni del sommatore viene generato simultaneamente. Questo significa che il calcolo del carry avviene in parallelo al calcolo della somma.
- *Questo fa sì che il tempo necessario per eseguire la somma sia indipendente dalla lunghezza del sommatore.*
- Tuttavia, man mano che *la dimensione della parola aumenta*, la distribuzione dell'hardware per eseguire l'addizione *diventa più complessa*.
  - Per questo motivo si utilizzano solo CLA fino a 4 ingressi.
  - Questo ci porta a dover utilizzare due o tre livelli di blocchi CLA per i sommatori di grandi dimensioni.
#### CLA per 4 bit
##### CLA: Livello porte
![[Pasted image 20231108122450.png|900]]
##### CLA: Livello transistori
Si può usare una porta AND-OR-INVERT per implementarlo.
- Questa struttura si chiama **Manchester Carry Chain**.
![[Pasted image 20231108133913.png]]
#### Somma di 4 bit con CLA
- Implementando porte XOR si può ottenere la somma con lo stesso circuito.
![[Pasted image 20231108132033.png]]
- Il ritardo è: $t_p = t_{G.P} + t_{xor} + 3 \cdot t_{CLA}$

> Per capire meglio cosa fai questo modulo, prima dobbiamo generare le $p_i$ e $g_i$. Il blocco prende questi valori di pi e gi  produce il valore di tutti carry e anque delle sume delle bit di quella posizione.
#### Somma di 16 bit con CLA
- Ha una scala logaritmica nei tempi, correlata al numero di bit coinvolti.
- Nei blocchi CLA (Carry Look-Ahead), *non si utilizzano direttamente gli ingressi, piuttosto si utilizzano blocchi G.P che fanno la XOR e la AND*.
- Per calcolare la somma è necessario retroalimentare i carry nell'ingresso dei diversi blocchi, come Cin, C4, C8, C12.
![[Pasted image 20231108131316.png|500]]
- Questo metodo di somma non è molto efficiente per valori bassi di somma, deve essere usato per somme a partire da 16 bit.
- A livello FPGA:
  - N>64 Carry Look-Ahead.
  - N<64 Carry Skip Adder.
##### Sistema di DDA
![[Pasted image 20231108154106.png|1000]]
#### Somma di 32 bit con CLA
![[Pasted image 20231108132533.png|900]]
- Ritardo: $t_p = t_{G.P} + t_{xor} + (2k-1)t_{CLA} \approx \log_{2}(N)-1$



### Brent-Kung Adder 
- Caso speciale di Look-Ahead.
- Utilizza il concetto del binary.
Si usa un'operazione che gode della proprietà associativa per calcolare il carry, che è la seguente:
![[Pasted image 20231109082233.png|300]]
Di seguito possiamo vedere come rispetta la proprietà associativa e come ci serve:
![[Pasted image 20231109082311.png]]
- **Somma di 8 bit con blocchi Brent-Kung Adder**
![[Pasted image 20231109082925.png]]
- **Ottenimento dei resti con blocco Brent-Kung Adder**
![[Pasted image 20231109083023.png]]
- Possiamo vedere che la somma e l'ottenimento dei resti vengono eseguiti in soli 3t, il che è un enorme vantaggio. L'equazione generica è: $$t_p \approx \log_2(N)$$
- Lo svantaggio di queste celle è la quantità di interconnessioni.
- I vantaggi sono la regolarità e il tempo.




### Carry Select Adder (CSA) 
- Questo divide la somma in K gruppi, per guadagnare velocità la logica è replicata e per ogni gruppo la somma assume un carry in ingresso (che può essere 0 o 1).
  - La somma e il carry di uscita corretti per ogni gruppo vengono selezionati dal carry di uscita del gruppo precedente. Il carry di uscita selezionato, a sua volta, viene utilizzato per selezionare la somma e il carry di uscita corretti del gruppo adiacente successivo.
  - Per sommare numeri grandi si utilizzano CSA gerarchici, che dividono la somma in più livelli.
- Un set di sommatori calcola la somma assumendo un carry in ingresso pari a 1 e l'altro un carry in ingresso pari a 0.
- La somma reale e il carry vengono selezionati utilizzando un mux basato sul carry del gruppo precedente.
- Questo è più lento del Carry Look-Ahead Adder ma è ideale per FPGA.
![[Pasted image 20231108120802.png|500]]
- In questo modo, il ritardo totale sarà il ritardo di un blocco + il ritardo del numero di multiplexer\bigoplus che ci sono.
#### CSA di più stadi
![[Pasted image 20231108120946.png|500]]
- Il CSA può essere diviso in più stadi.
- Nella figura è diviso in gruppi di N/2 bit che a loro volta sono divisi in N/4 bit.
- Se si dividessero i gruppi fino ad arrivare a sottogruppi di 1 bit ciascuno, l'architettura del sommatore sarebbe la stessa del conditional sum adder, per cui consideriamo questo un caso particolare di CSA.
#### Cercando il set ideale di sommatori per maggiore velocità
- Abbiamo che il numero di bit sommati è $N = m \cdot p$.
- Inoltre, sappiamo che $t_{total} = m \cdot t_0 + (p-1) \cdot t_{mux}$.
  - Dove p è il numero di blocchi.
  - m è il numero di somme per blocco.
- Per trovare il valore minimo di ritardo possibile, deriviamo e uguagliamo a 0, ottenendo: $$t_{total,min} = 2 \sqrt{N \cdot t_0 \cdot t_{mux}} - t_{mux}$$
- Dove $$p = \sqrt{\frac{N \cdot t_0}{t_{mux}}}$$



### Sommatore condizionale 
- Questo sommatore è implementato in più livelli.
  - Può essere considerato come un CSA con il massimo numero possibile di livelli.
- L'operazione di selezione del carry nel primo livello è eseguita da gruppi di 1 bit. Nel livello successivo, due gruppi adiacenti si fondono per dare il risultato di un'operazione di selezione del carry di 2 bit. Questa fusione è ripetuta fino a quando gli ultimi due gruppi si fondono per generare la somma finale e il carry di uscita.
- Questo sommatore è il più veloce della famiglia.
  - Il problema è se viene implementato correttamente.
![[Pasted image 20240218204720.png|500]] ![[Pasted image 20240218202549.png|200]]
- Nel livello due, i risultati del livello uno si fondono. Questa fusione avviene attraverso l'accoppiamento delle colonne consecutive del livello 1. Per un sommatore di N bit, le colonne sono accoppiate nella forma $(i, i+1)$ per i che va da 0 a N-2.
- I bit meno significativi del carry (LSC) in una determinata posizione i di ogni coppia selezionano i bit di somma e di carry della posizione i+1 per il livello successivo di elaborazione.
- Se il least significant carry (LSC) è 0, vengono selezionati i bit calcolati per il carry di ingresso 0, altrimenti vengono selezionati i bit corrispondenti al carry di ingresso 1.
- In questo modo, due bit vengono sommati assumendo un determinato valore per il carry di ingresso.
- Permette di implementare il pipeline.
#### Esempio di 3 bit
![[Pasted image 20240218202614.png]]
- Nell'esempio precedente possiamo vedere il sommatore CSA che somma numeri di 3 bit.
- Nel primo livello ogni gruppo consiste di un bit. Il livello aggiunge i bit della posizione i supponendo il carry di ingresso 0 e 1.
- Nel livello successivo le tre colonne si dividono in due gruppi (come mostra la linea tratteggiata). La colonna nella posizione del bit 0 forma il primo gruppo e le altre due colonne il secondo gruppo. La selezione appropriata in ogni gruppo da parte del LSC è mostrata con la linea diagonale.
- L'LSC di ogni gruppo determina quale dei due bit della colonna successiva verrà ridotto al livello successivo di elaborazione.
- Se l'LSC è 0, vengono selezionati i bit superiori della colonna successiva, altrimenti vengono selezionati i due bit inferiori della colonna successiva.
- Per il secondo gruppo, il bit di somma della prima colonna scende anche al secondo livello. Gli LSC nel primo livello sono evidenziati in grassetto nel grafico.
- Infine, nel livello successivo, i due gruppi formati nel livello precedente si combinano e l'LSC seleziona uno dei due gruppi di 3 bit per passare al livello successivo. Poiché l'LSC è 1, seleziona il gruppo inferiore.
#### Esempio N bit
![[Pasted image 20240218210102.png]]



### Altri sommatori interessanti
#### Hybrid Ripple Carry e Carry Look-Ahead Adder
- Invece di costruire un grande sommatore CLA usando più livelli gerarchici di logica CLA, il carry può semplicemente propagarsi tra i blocchi.
- Questo tipo di sommatore sarà più veloce di un RCA e occuperà meno area di un sommatore gerarchico CLA.
- Questo perché abbiamo un solo livello di logica CLA.
![[Pasted image 20240218201630.png]]

#### Binary Carry Look-Ahead Adder (BCLA)
- Un BCLA lavora con un gruppo di due bit adiacenti, dal LSB al MSB, combinando i bit in gruppi di due per formare un nuovo gruppo di bit e il relativo carry.
![[Pasted image 20240218201917.png|300]]
- Ci sono molti modi per implementare queste equazioni. L'obiettivo è eseguire questa implementazione per ogni posizione di bit spostandosi dai LSB ai MSB, il che richiederà una successiva applicazione dell'operatore * nelle posizioni di due bit adiacenti.
- Per un sommatore di N bit saranno necessari N-1 stadi di implementazione degli operatori.



## Sommatori Carry Save e Compressori 
- Invece di eseguire direttamente la somma binaria come fa un Full Adder, un CSA opera in due fasi: *generazione di sommatori parziali e propagazione dei carry*.
- Nella fase di *generazione di sommatori parziali*, i bit degli operandi *vengono sommati senza considerare i carry*. *Questo produce due risultati: la somma dei bit di dati (S) e una rappresentazione in eccesso-3 della somma dei bit di dati (G)*.
- Nella fase di *propagazione dei carry*, *i bit di carry vengono calcolati a partire dalle somme parziali generate* nella fase precedente.
- Quando un CSA riduce tre operandi a due, *non propaga il carry*. Piuttosto, *salva il carry nella posizione di bit significativa successiva*. Questo significa che l'addizione ridurrà tre operandi a due senza avere un ritardo di propagazione del carry.
- Per questo sommatore, per il modo in cui opera, è anche chiamato compressore 3:2. A differenza dei full adders, *questo compressore 3 a 2 è associato a parole e non a bit*.
![[Pasted image 20240219092650.png]]
**Osservazioni:**
- Il principale vantaggio di un CSA è la sua capacità di sommare più operandi in parallelo senza generare carry in ogni stadio, il che lo rende più veloce di altri tipi di sommatori per alcune applicazioni, come moltiplicatori e sommatori ad alta velocità.
- In termini di timing e area, il CSA è uno dei sommatori più efficienti e utilizzati per accelerare i design digitali di sistemi di elaborazione dei segnali che gestiscono più operandi per l'addizione e la moltiplicazione.
- Esistono molte tecniche che utilizzano CSA per sommare più di tre operandi. Queste tecniche sono molto utilizzate per ridurre i prodotti parziali nel design dei moltiplicatori.
### Notazione dei punti
- La notazione dei punti viene utilizzata per spiegare diverse tecniche di riduzione.
- In questa notazione, ogni bit nella somma di due operandi è rappresentato da un punto.
- Una tecnica di riduzione 3:2 riduce tre strati di prodotti parziali a due.
![[Pasted image 20240219094109.png]]
#### Gestione dei punti
- Questa tecnica considera il numero di punti in ogni colonna; nel caso in cui appaia un punto isolato in una colonna, viene semplicemente ridotto al livello di logica successivo.
- Quando ci sono due punti in una sola colonna, vengono aggiunti utilizzando un half adder; il punto per la somma viene lasciato cadere nella stessa colonna e il punto per il carry viene posizionato nella colonna di bit significativa successiva. L'uso di un half adder per questa operazione è noto anche come riduzione 2:2.
- I tre punti in una colonna vengono ridotti a due utilizzando un full adder. In questo caso, il punto per la somma viene posizionato nella stessa posizione di bit e il punto per il carry viene posizionato nella posizione di bit significativa successiva.
![[Pasted image 20240219094125.png]]
### Compressori di ordine superiore
- Basandosi sul concetto di CSA, possono essere sviluppati altri blocchi di compressori.
- Comprimendo più operandi, il compressore lavora in cascata.
- Se questi compressori vengono implementati utilizzando la logica della catena del carry, si possono ottenere migliori risultati di timing e di area rispetto all'uso di CSA.
- Le somme multi-operando in ASIC (circuito integrato a specifica applicazione) sono generalmente implementate utilizzando CSA basati su alberi di riduzione Wallace e Dadda.
- Con LUTs e catene del carry nelle FPGA, l'implementazione di un contatore offre una migliore alternativa alla somma di più operandi basati su CSA.
  - Questi contatori aggiungono tutti i bit in una o più colonne per utilizzare meglio le risorse delle FPGA.
#### Esempi
![[Pasted image 20240219103551.png]]
- Ogni LUT calcola la somma rispettiva, i bit di carry0 e carry1 del compressore.
- Si possono anche costruire contatori di diverse dimensioni, e una combinazione di questi può essere utilizzata per ridurre diversi operandi a due.
- Nella figura seguente, si possono vedere contatori 15:4, 4:3 e 3:2 che lavorano in cascata per comprimere una matrice 15 x 15.
![[Pasted image 20240219103617.png]]
#### GPC
![[Pasted image 20240219103636.png]] ![[Pasted image 20240219103648.png]]
I GPC offrono flessibilità una volta assegnati a un'FPGA.
Il problema di configurare le dimensioni dei GPC per mappare su FPGA per la somma di più operandi è un problema completo - NP.
Il problema si risolve con la "programmazione intera" e si riporta che il metodo supera l'applicazione basata su alberi di somma dal punto di vista dell'area e del tempo.
Le FPGA sono le più adatte per i contatori e gli alberi di compressione basati su GPC.
Per utilizzare completamente le FPGA basate su 6-LUT, è meglio che ogni contatore o GPC abbia 6 bit di ingresso e 3 (o 4 meglio) bit di uscita, come si vede nelle immagini seguenti.
I quattro bit di uscita sono favoriti poiché le LUT in molte FPGA vengono in gruppi di due con ingresso a 6 bit condiviso, e un 6:3 GPC sprecherebbe una LUT in ogni compressore, come mostrato nella seconda immagine.
![[Pasted image 20240219103704.png]] ![[Pasted image 20240219103716.png]]
### Riduzione dell'Albero di Somma
- Anche se diversi dispositivi delle famiglie FPGA offrono moltiplicatori integrati, gli alberi compressori sono ancora critici in molte applicazioni.
- L'albero di compressione è il primo blocco di costruzione per ridurre i requisiti del numero di CPA per la somma di più operatori.
**Esempio:**
- Nell'esempio seguente, vengono aggiunti 5 operatori segnati nei formati S(6.5), S(8.3), S(11.7) e S(12.6).
- La logica di estensione del segno che viene costruita per prima, viene eliminata calcolando un vettore di correzione e aggiungendolo come sesto strato nella rappresentazione dei punti.
- Nella figura si mostra che la disposizione dei punti su una griglia richiede un albero di compressione per ridurre il numero di punti in ogni colonna a 2. Questo può essere dimostrato utilizzando qualsiasi tecnica di riduzione. Qui utilizzeremo la riduzione di Dadda.
- Successivamente, i due operandi vengono inseriti in un CPA per la somma finale.
![[Pasted image 20240219121007.png]]



### Trasformazioni di Algoritmi per CSA
- Il CSA svolge un ruolo importante nell'implementazione di applicazioni DSP ad alte prestazioni in hardware.
- Mentre si assegna un grafico di flusso dei dati all'architettura, si osserva che il grafico mostra qualsiasi uso potenziale del CSA e, di conseguenza, il grafico viene modificato.

**Esempio di base**
- Ad esempio, consideriamo l'implementazione delle seguenti equazioni:
  - $d[n] = a[n] + b[n] + c[n]$
  - $y[n] = d[n-1] \cdot e[n]$
- Le equazioni vengono convertite in DFG nella figura (a).
- Questo viene modificato usando CSA per comprimere $a[n] + b[n] + c[n]$ in due numeri, che vengono poi sommati utilizzando un CPA. Questo DFG trasformato è mostrato nella figura (b).
![[Pasted image 20240219121025.png|300]] ![[Pasted image 20240219122713.png|300]]

#### Trasformazioni per somme
- Questa tecnica di estrazione di somma di più operandi può essere estesa ai grafici di flusso dei dati, dove si osserva che i grafici mostrano qualsiasi uso potenziale di CSA e alberi compressori.
- I grafici vengono prima trasformati per utilizzare in modo ottimale gli alberi compressori e poi mappati in hardware.
- Queste trasformazioni hanno dimostrato di migliorare significativamente il design hardware delle applicazioni di elaborazione dei segnali.
- Le operazioni di somma multipla sono le più facili di tutte le trasformazioni.
![[Pasted image 20240219121059.png]] ![[Pasted image 20240219121109.png]]


#### Trasformazioni per operazioni di somma e moltiplicazione  
- Similmente a quanto sopra, la seguente operazione di somma e moltiplicazione può essere rappresentata con il suo equivalente DFG: $op1 \cdot (op2 + op3)$
- Il DFG può essere trasformato per utilizzare efficacemente un albero compressore.
- Un'implementazione diretta richiede un CPA per eseguire $op2 + op3$, e poi il risultato di questa operazione viene moltiplicato per $op1$.
- L'architettura di un moltiplicatore comprende un albero compressore e un CPA.
- Per implementare il calcolo, sono necessari 2 CPA.
- Una semplice trasformazione utilizza la proprietà distributiva dell'operatore di moltiplicazione:
  - $op1 \cdot op2 + op1 \cdot op3$
- Questa rappresentazione dell'espressione ora richiede un albero di compressione, seguito da un CPA per calcolare il valore finale.
- Il DFG associato e la trasformazione sono visibili nella figura seguente.
![[Pasted image 20240219121126.png]]
^1721665184304


#### Trasformazioni per cascata di moltiplicazioni  
- Estendere la tecnica di generazione di somme parziali e carry può anche ottimizzare l'implementazione di una cascata di moltiplicazioni: $prod = op1 \cdot op2 \cdot op3 \cdot op4$
- La trasformazione genera prima i PP per $op1 \cdot op2$ e li riduce ai PP, s1 e c1: $(s1; c1) = op1 \cdot op2$
- Questi 2 PP vengono moltiplicati indipendentemente con $op3$, generando 2 set di PP che vengono ridotti di nuovo a 2 PP, s2 e c2, utilizzando un albero compressore: $(s2, c2) = s1 \cdot op3 + c1 \cdot op3$
- Questi due PP vengono moltiplicati con $op4$ per generare 2 set di PP che vengono compressi di nuovo per calcolare i 2 PP finali, s3 e c3. Questi due PP vengono poi aggiunti utilizzando un CPA per calcolare il prodotto finale: $(s3, c3) = s2 \cdot op4 + c2 \cdot op4$... $prod = s3 + c3$
- Questo è illustrato nell'immagine seguente.
![[Pasted image 20240219123736.png]]
^1721665184307

## Somma UNISA

### Implementare la sottrazione con il circuito della somma 
- Prima dobbiamo cambiare la sottrazione in una somma: $$A - B = A + (-B)$$- E se abbiamo il complemento a 2, in questo modo si applicherebbe già la sottrazione.
- Per poter invertire un ingresso quando è sottrazione, si usa un multiplexer per selezionare il carry di ingresso.
![[Pasted image 20231027143231.png|400]]


### Sommatore di 4 numeri di 4 bit
![[Pasted image 20231106090059.png|500]]
- Quando si sommano 2 numeri di 4 bit, è necessario un numero di 5 bit per il risultato.
  - In questo caso, poiché stiamo sommando 4 numeri di 4 bit, penseremmo di aver bisogno di 7 bit per la struttura, ma non è così.
    - Poiché la somma di 2 numeri può dare 32 possibilità di 3, 48 e di 4, 64 bit.
    - Quindi, abbiamo bisogno solo di 6 bit, per cui l'ultimo bit sarà sempre 0.

### Sommatore di 4 numeri di 4 bit ottimizzato in velocità(CSA)
- Ci rendiamo conto che non è necessario inviare il resto di ogni somma al sommatore successivo.
  - Ad esempio, il resto della somma di $a0$ e $b0$ potrebbe essere sommato con $a1$ e $b1$ o anche con $d1$, quindi possiamo semplificare il sistema.
![[Pasted image 20231106091127.png|500]]
- Questa struttura si chiama carry save e riduce il ritardo da 8t a 6t.
- Bisogna anche tenere presente che aggiungiamo il blocco VMA alla fine.
  - VMA (vector multiplier address).
  - Questo blocco esegue la somma con più superficie di silicio ma molto più rapidamente.

### Sommatore ottimizzato al massimo in risorse( Sommatore con state machine)
- Se voglio semplificare al massimo la struttura utilizzata senza considerare il ritardo per sommare una quantità di n bit, possiamo usare il pipeline per utilizzare solo un blocco sommatore di 1 bit.
![[Pasted image 20231106092758.png]]


# Multiplicatori

## Multiplicatori Paralleli
- I progettisti di sistemi ad alte prestazioni sono interessati a sviluppare moltiplicatori che calcolino il prodotto in un solo ciclo.
  - Per ottenere questo, vengono progettate architetture di moltiplicatori paralleli.
  - Un CSA è un blocco fondamentale in queste architetture.
- I prodotti parziali vengono ridotti prima a due numeri utilizzando un albero CSA.
- Questi due numeri vengono poi sommati per ottenere il prodotto finale.
- Attualmente, le FPGA possiedono un gran numero di sommatori dedicati. Questi sommatori possono sommare tre operandi. Gli alberi riduttori possono ridurre il numero di prodotti parziali a tre invece di due per sfruttare completamente questi blocchi.
- Qualsiasi architettura *multiplicatrice parallela consta di tre operazioni* fondamentali:
  1. Generazione del prodotto parziale
  2. Riduzione del prodotto parziale
  3. Calcolo della somma finale utilizzando un CPA (Carry Propagation Adder).
![[Pasted image 20240219094303.png]]




### Generazione dei Prodotti Parziali
- Durante la moltiplicazione di due numeri di N bit, a e b, vengono generati i prodotti parziali.
- Questi possono essere generati utilizzando il *metodo di ANDing* o implementando un algoritmo di *ricodifica di Booth*.


#### Metodo ANDing 
- Genera un prodotto parziale PPi attraverso un'operazione AND di ogni bit ai del moltiplicatore con tutti i bit del moltiplicando b.
- Ogni PPi è spostato a sinistra di i posizioni prima che i prodotti parziali siano sommati per colonne per produrre il risultato finale.
![[Pasted image 20240219094717.png]]


#### Moltiplicatore di Booth 
- Ridurre il numero di prodotti parziali è una tecnica di ottimizzazione utilizzata in molti progetti.
- Il moltiplicatore modificato di Booth (MBR) è una di queste tecniche.
- Quando si moltiplicano due numeri di N bit con segno, a e b, la tecnica genera un prodotto parziale per ciascuno attraverso l'accoppiamento di tutti i bit di b in gruppi di due bit.
- La tecnica, passando dal LSB al MSB di b, accoppia due bit insieme per formare un gruppo che verrà ricodificato utilizzando l'algoritmo MBR.
- I due bit di un gruppo possono essere 00, 01, 10, 11 (binario).
- La moltiplicazione per 00, 01 e 10 risulta semplicemente in 0, a e 2a = a << 1 rispettivamente, dove ogni prodotto parziale è calcolato come un numero.
- La quarta possibilità è 11 binario che è uguale a 3 decimale, uguale a 2 + 1, e uno spostamento semplice potrebbe non generare il prodotto parziale richiesto. Questa moltiplicazione risulterà in due prodotti parziali che sono a e 2a. Questo significa che nel peggiore dei casi il moltiplicatore avrà N prodotti parziali.
- Il problema del caso 11 per generare due prodotti parziali è risolto utilizzando l'algoritmo di ricodifica di Booth.
- Questo algoritmo lavora con gruppi di due bit ma ricodifica ogni gruppo per utilizzare uno dei cinque valori equivalenti: 0, 1, 2, -1, -2. La moltiplicazione per tutti questi numeri risulta in un prodotto parziale per ciascuno.
- Questi valori equivalenti sono codificati indicizzandoli in una LUT. Questa LUT è calcolata utilizzando la proprietà della catena dei numeri vista precedentemente.
- Questa proprietà è osservata in ogni coppia di bit dal LSB al MSB.
- Per verificare la proprietà della catena, è richiesto anche il MSB della coppia precedente insieme ai due bit della coppia sotto considerazione. Per la prima coppia si aggiunge uno zero a destra.
- La seguente tabella mostra la proprietà della catena che lavora con tutti i numeri possibili di 3 bit per generare una tabella che viene poi usata per ricodificare.
![[Pasted image 20240219115601.png]]
##### Esempio
- In questo esempio vengono moltiplicati due numeri di 8 bit 10101101 e 10001101 usando la tecnica descritta sopra.
- La tecnica separa prima i bit del moltiplicatore in gruppi di due bit. Poi il MSB del gruppo precedente ricodifica ogni gruppo usando la tabella precedente. Si suppone uno zero per il MSB del gruppo meno significativo poiché non ha un gruppo precedente.
- Gli 8 gruppi con il MSB del gruppo precedente sono:
  - 100001110010
- Si osserva nella tabella che i numeri sono ricodificati a -2, 1, -1 e 1 e i quattro prodotti parziali sono generati come mostrato nell'immagine successiva.
- Per un numero ricodificato 1 nel moltiplicatore, il moltiplicando viene semplicemente copiato.
- Poiché ogni prodotto parziale è generato da una coppia di 2 bit del moltiplicatore, il prodotto parziale i viene spostato di 2i posizioni a sinistra.
- Per il secondo numero ricodificato del moltiplicatore che è -1, il complemento a 2 del moltiplicando viene copiato.
- I prodotti parziali sono generati per tutti i numeri ricodificati; per l'ultimo numero di -2, il complemento a 2 del prodotto parziale è spostato più a sinistra di una posizione di bit per eseguire la moltiplicazione per due.
- Si estende il segno dei quattro prodotti parziali e poi vengono sommati per ottenere il prodotto finale.
- La logica di eliminazione dell'estensione del segno potrebbe essere utilizzata per ridurre la logica di implementazione hardware.
![[Pasted image 20240219120020.png]]
##### Deduczione matematica del Moltiplicatore BOOTH
- Questo moltiplicatore fa uso di un barrel shifter per moltiplicare.
- Riscrivendo un numero ci rendiamo conto che possiamo farlo in funzione dei parametri Ci e del barrel shifter.
![[Pasted image 20231106112127.png|1000]]
- In questa deduzione di X si può vedere:
  - Il $2^4,2^2,2^0$ fa riferimento a come si sposta un posto a sinistra e come si lascia uno a 0 al momento di fare i prodotti.
  - I $C_i$ si ottengono dal decodificatore.
![[Pasted image 20231106112130.png|300]]
##### Moltiplicatore di Booth dinamico
- Non ha molto senso con variabili perché richiede molta logica.
![[Pasted image 20240219120112.png]]
##### Moltiplicatore di Booth riutilizzando risorse
![[Pasted image 20231106113153.png|500]]



### Riduzione dei Prodotti Parziali  
- Utilizzando la notazione a punti, tutti i prodotti parziali formano una disposizione di punti in un parallelogramma. I punti di ogni colonna saranno aggiunti per calcolare il risultato finale.
- In generale, per un moltiplicatore di N1 bit per N2 bit, si utilizzano le seguenti quattro tecniche per ridurre N1 strati di prodotti parziali a due strati per la loro somma finale utilizzando qualsiasi CPA:
  - Riduzione Carry Save
  - Riduzione Dual Carry Save
  - Riduzione ad Albero di Wallace
  - Riduzione ad Albero di Dadda
- Le tecniche sono descritte per compressori 3:2 ma possono essere facilmente estese ad altri compressori.



#### Riduzione Carry Save 
- Si riducono i primi tre strati dei prodotti parziali utilizzando CSA.
- Nei tre strati selezionati, i bit isolati in una colonna cadono semplicemente nella stessa colonna, le colonne con due bit vengono ridotte a due bit utilizzando half adders e le colonne con tre bit vengono ridotte a due bit utilizzando full adders.
- Quando si somma utilizzando gli HA e FA, il punto che rappresenta il bit di somma cade nella stessa colonna mentre il punto del carry viene posizionato nella colonna successiva di bit più significativo.
- Una volta che i primi tre prodotti parziali sono ridotti a due strati, il quarto prodotto parziale della composizione originale viene raggruppato con i due strati precedenti per formare un nuovo gruppo di tre strati. Questi tre strati vengono ridotti nuovamente a due utilizzando la tecnica CSA.
- Questo processo si ripete fino a quando l'intero insieme è ridotto a due strati di numeri.
- Come risultato si ottengono dei bit di prodotto meno significativi, denominati bit di prodotto libero, e il resto dei bit appare in due strati che vengono sommati utilizzando qualsiasi CPA.
![[Pasted image 20240219094830.png|400]] 
![[Pasted image 20240219094832.png|400]]


#### Riduzione Dual Carry Save 
- I prodotti parziali sono divisi in due gruppi di uguale dimensione.
- Lo schema di Riduzione Carry Save viene applicato simultaneamente in entrambi i sotto-gruppi.
- Come risultato si ottengono due insiemi di strati di prodotti parziali in ciascun sotto-gruppo.
- La tecnica infine risulta in quattro strati di prodotti parziali.
- Questi strati vengono poi ridotti a un gruppo di tre e infine a un gruppo di due strati.


#### Riduzione ad Albero di Wallace 
- I prodotti parziali sono divisi in gruppi di tre prodotti parziali ciascuno.
- A differenza della riduzione temporale dei due metodi precedenti, questi gruppi di prodotti parziali vengono ridotti simultaneamente utilizzando i CSA.
- Ogni strato di CSA comprime tre strati in due strati. Questi due strati di ciascun gruppo vengono raggruppati in insiemi di tre strati.
- Nel livello successivo si riducono nuovamente tre strati a due strati, questo processo continuerà fino a quando rimarranno solo due file.
- Infine, qualsiasi CPA può essere utilizzato per calcolare il prodotto finale.
- Questa riduzione è uno degli schemi più utilizzati nelle architetture dei moltiplicatori.
- La riduzione viene eseguita in parallelo in gruppi di tre.
- Man mano che il numero di prodotti parziali aumenta, avremo un incremento logaritmico nel numero di livelli del sommatore.
- Il numero di livelli del sommatore rappresenta il ritardo del percorso critico.
![[Pasted image 20240219094950.png|900]] ![[Pasted image 20240219095012.png|400]]
- Ogni livello del sommatore possiede un ritardo di FA nel suo percorso.
![[Pasted image 20240219101705.png]]


#### Riduzione ad Albero di Dadda 
- Gli alberi Dadda richiedono lo stesso numero di livelli del sommatore degli alberi Wallace, quindi il percorso critico di timing è lo stesso.
  - Minimizza il numero di HA e FA in ogni livello logico.
- Se si osserva la tabella precedente della riduzione di Wallace, i limiti superiori della colonna di numeri di prodotti parziali sono i seguenti: 2;3;4;6;9;13;19;28;...
- Ogni numero rappresenta il numero massimo di prodotti parziali in ogni livello che a sua volta richiede un numero fisso di livelli del sommatore.
- La sequenza mostra anche che si possono ottenere due prodotti parziali a partire da un massimo di tre, tre si possono ottenere da quattro, quattro da sei e così via.
- La Riduzione ad Albero di Dadda considera ogni colonna separatamente e riduce il numero di livelli logici di una colonna al numero massimo di strati nel livello successivo.
  - Ad esempio, per ridurre un moltiplicatore di 12x12 bit, la riduzione di Wallace riduce da 12 prodotti a 8 mentre lo schema Dadda prima li riduce al massimo numero di strati nel gruppo successivo, ovvero nove. Questa azione richiederà lo stesso numero di livelli logici ma risulterà in meno hardware.
- In questa riduzione, se il numero di punti in una colonna è inferiore al numero massimo di prodotti parziali che si vuole ridurre nel livello attuale, questi vengono semplicemente passati al livello successivo senza alcun processamento.
- Le colonne che hanno più punti rispetto ai punti richiesti per il livello successivo vengono ridotte per raggiungere il numero massimo di strati nel livello successivo.
^1721665184334

![[Pasted image 20240219095111.png]]

#### Un'altra strategia
- Una moltiplicazione può essere suddivisa in un numero di moltiplicazioni più piccole.
- Ad esempio, la moltiplicazione di 16 bit può essere eseguita considerando gli operandi a e b come quattro operandi di 8 bit, prendendo i bit più significativi da un lato e i meno significativi dall'altro otterremmo aH, aL, bH e bL.
- La decomposizione matematica dell'operazione è data come segue:
  - aL = a7a6a5a4a3a2a1a0
  - aH = a15a14a13a12a11a10a9a8
  - bL = b7b6b5b4b3b2b1b0
  - b = b15b14b13b12b11b10b9b8
  - (aL+2^8aH)x(bL+2^8bH) = aLxbL+aLxbH2^8+aHxbL2^8+aHxbH2^16
- Queste quattro moltiplicazioni di 8x8 bit possono essere eseguite in parallelo per poi ottenere il risultato finale del moltiplicatore di 16x16 bit.

![[Pasted image 20240219102957.png]]

## Moltiplicazione Segnata in Complemento a Due
### Introduzione
![[Pasted image 20240219110420.png]]
- A causa del cambiamento di i, tutti i PPs sono numeri con segni di diversa larghezza.
- Tutti questi numeri devono essere allineati a sinistra tramite la logica di estensione del segno prima di essere sommati per calcolare il prodotto finale.
- Poiché il MSB di a ha un peso negativo, la moltiplicazione di questo bit risulta in un PP che è il complemento a 2 del moltiplicando.
![[Pasted image 20240219110511.png]]
- Si estende il segno dei N1 prodotti parziali e si sommano per ottenere il prodotto finale.
#### Esempio
- La figura seguente mostra una moltiplicazione segnata di 4x4 bit.
- I bit di segno dei primi 3 PPs vengono estesi e mostrati in grassetto.
- Il complemento a 2 dell'ultimo PP viene preso per soddisfare il peso negativo del MSB del moltiplicatore.
- Se il moltiplicatore segnato viene implementato come in questo esempio, la logica di estensione del segno occuperà un'area significativa dell'albero di compressione.
- Si desidera eliminare in qualche modo questa logica dal moltiplicatore.

![[Pasted image 20240219110927.png]]


### Eliminazione dell'Estensione del Segno
#### Introduzione
- Una semplice osservazione in un numero esteso di segni ci porta a una tecnica efficace per l'eliminazione della logica di estensione dei segni.
- Un equivalente del numero esteso di segni si calcola invertendo il bit di segno e aggiungendo un 1 nella posizione del bit di segno, e estendendo il numero con tutti gli 1.
- La seguente immagine spiega il calcolo in un numero positivo.

![[Pasted image 20240219111609.png]]
#### Vettore di Correzione
- Lo strumento genera questo vettore di correzione.
- Nell'immagine seguente si vedono i passaggi necessari nella logica di eliminazione del segno dell'estensione del segno in un moltiplicatore segnato di 11x6 bit.
- Prima, il MSB di tutti i PPs, tranne l'ultimo, viene invertito, si aggiunge un 1 nella posizione del bit di segno, e il numero viene esteso con tutti gli 1.
- Per l'ultimo PP, il complemento a 2 viene calcolato invertendo tutti i bit e aggiungendo 1 alla posizione LSB.
- Il MSB dell'ultimo PP viene invertito e si aggiunge 1 a questa posizione di bit per l'estensione del segno.
- Tutti questi 1 vengono sommati per ottenere un vettore di correzione (CV).
- Tutti gli 1 vengono rimossi, il CV viene semplicemente sommato e gestisce la logica dell'estensione del segno.
![[Pasted image 20240219111840.png]]
##### Esempio
- Nell'esempio seguente si trova il CV per un moltiplicatore segnato di 4x4 bit e viene utilizzato per moltiplicare 2 numeri: 0011 e 1101.
- Nella figura "a" della seguente immagine, tutti gli 1 per l'estensione del segno e i complementi a 2 vengono sommati, e il CV = 0001_0000.
- Applicando la logica dell'eliminazione dell'estensione del segno e sommando il CV ai PPs, la moltiplicazione viene eseguita di nuovo dando lo stesso risultato, come si può vedere nella figura "b" della seguente immagine.
- Poiché il CV ha un solo bit diverso da zero, il bit viene aggiunto al primo PP (mostrato in grigio).
- Questa tecnica risparmia area e quindi è molto efficace.

![[Pasted image 20240219113409.png]]



### Digit Canonico con Segno
- Questo concetto si può applicare solo alle costanti
- Finora sono stati rappresentati solo numeri in forma di complemento a 2, dove ogni bit è 0 o 1.
- Esistono anche altre forme per rappresentare numeri.
- Alcune poche sono efficaci per la progettazione di sistemi di elaborazione del segnale, come il digito canonico con segno (CSD).
- Nel CSD, un digito può essere 1, 0 o -1.
- La rappresentazione limita l'occorrenza di 2 digiti distinti da zero consecutivi nel numero, generando una rappresentazione unica con un numero minimo di digiti distinti da zero.
- Il CSD di un numero si può calcolare utilizzando la proprietà della catena dei numeri.
- Questa proprietà, passando dal LSB al MSB, trova successivamente catene di 1 e le sostituisce con un valore equivalente, utilizzando 1, 0 o -1.
- Considerando il numero 7, questo può essere scritto come 8-1, o in CSD come:
  - 0111 = 1000-1 = 1001
- Il bit con una barra ha un peso negativo e gli altri hanno un peso positivo.
- In modo simile, il 31 può essere scritto come 32-1, o in CSD come:
  - 011111 = 100000-1 = 100001
- In modo equivalente, una catena di 1 viene sostituita con 1 nel 1 meno significativo della catena, e un 1 viene posizionato dopo il 1 più significativo della catena, mostrando che tutti gli altri bit vengono riempiti di zeri.
- Si può estendere in modo banale questa trasformazione a qualsiasi catena di 1 nella rappresentazione binaria di un numero.
- La proprietà della catena può essere applicata ricorsivamente nelle rappresentazioni binarie di un numero.
- Il numero trasformato ha un numero minimo di bit distinti da zero.
![[Pasted image 20240219113514.png]]



## Moltiplicazione per Costanti

### Introduzione

#### Dove si utilizza?
- In molti sistemi di elaborazione digitale (DSP) e algoritmi di comunicazione, una grande proporzione di moltiplicazioni sono numeri costanti.
- Ad esempio:
  - Filtri di risposta a impulso finito (FIR).
  - Filtri di risposta a impulso infinito (IIR).
  - La trasformata discreta del coseno (DCT).
  - La trasformata discreta inversa del coseno (IDCT).
  - La trasformata veloce di Fourier (FFT).
  - La trasformata veloce di Fourier inversa (IFFT).
- Per un'architettura completamente dedicata (FDA), dove la moltiplicazione per una costante viene assegnata a un moltiplicatore dedicato, non è richiesta la complessità di un moltiplicatore di uso generale.
- La rappresentazione binaria di una costante mostra chiaramente i bit distinti da zero che richiedono la generazione di prodotti parziali (PP), mentre i bit che sono zero nella rappresentazione possono essere ignorati per l'operazione di generazione di PP.
- La rappresentazione CSD (codifica canonica) può ridurre ulteriormente il numero di prodotti parziali.
#### Concetto
- È un codice di cifra segnata radix-2.
- Codifica una costante utilizzando cifre segnate 1, 0 e -1.
- Rappresentazione di costante di N bit:
![[Pasted image 20240219181935.png]]
- Proprietà:
  - Non ci sono due bit consecutivi nella rappresentazione CSD di un numero che non siano zero.
  - La rappresentazione CSD di un numero utilizza un numero minimo di cifre diverse da zero.
  - La rappresentazione CSD di un numero è unica.
La rappresentazione CSD di un numero si può calcolare ricorsivamente utilizzando la proprietà della catena.
L'LSB in una catena di 1 viene cambiato in 1 che rappresenta -1, e tutti gli altri 1 nella catena vengono sostituiti da zeri, e lo 0 che segna la fine della catena viene cambiato in 1.
Dopo aver sostituito una catena con le sue cifre CSD equivalenti, il numero viene osservato nuovamente spostandosi dalla cifra codificata al MSB per contenere eventuali altre catene di 1.
Il processo si ripete fino a quando non si trova una catena di 1 nel numero.


# Altre Strategie


## Operazioni con Barrel Shifter 
### Divisione con Spostatore
- Un spostatore logico di N bit implementa l'operazione x >> s, dove s è un numero intero segnato.
- Si implementa attraverso il collegamento di tutti gli spostamenti possibili come ingresso di un multiplexor e poi si seleziona l'uscita appropriata utilizzando il numero s.
- Questo spostatore può arrivare a implementare divisioni ma queste sarebbero solo con un multiplo di 2.
#### Esempi di Progettazione di Spostatori
- Nell'immagine a sinistra si può osservare il progetto dello spostatore, dove x è l'operatore di ingresso e tutti gli spostamenti possibili vengono eseguiti in anticipo e inseriti nel multiplexor in cui il numero s viene utilizzato come selettore.
- Per un numero s negativo, lo spostatore prenderà il valore positivo ed eseguirà lo spostamento a sinistra.
- Il progetto può essere facilmente esteso per gestire spostamenti aritmetici e logici, come possiamo osservare nell'immagine a destra.
- Per questo, prima si deve selezionare il bit di segno o 0 per allegarlo appropriatamente a sinistra dell'operatore per eseguire un'operazione di spostamento a destra.
- Per un'operazione di spostamento a sinistra, il progetto per entrambe, lo spostamento aritmetico e logico, è lo stesso.
- Quando non ci sono abbastanza bit di segno ridondanti, lo spostamento a sinistra causerà overflow.
^1721665184346

![[Pasted image 20240219091600.png]]
### Barrel Shifter
- Invece di usare un multiplexor con ingressi multipli, un barrel shifter può anche essere costruito in modo gerarchico.
- Si possono implementare facilmente pipeline in questo progetto. La tecnica può funzionare sia per lo spostamento a destra che a sinistra.
- Per x >> s, la tecnica lavora considerando s come un numero in complemento a due con segno in cui il bit di segno ha peso negativo e il resto dei bit ha peso positivo.
- Passando dai bit più significativi ai meno significativi, ogni fase del barrel shifter serve solo un bit ed esegue lo spostamento richiesto uguale al peso del bit.
- Questo permette di eseguire divisioni che non sono solo potenze di 2.
#### Esempio di Barrel Shifter 16 bit
- Nell'immagine della diapositiva successiva viene presentato un barrel shifter capace di spostare un numero x di 16 bit per un numero s di 5 bit segnato. Con ciò lo spostatore può eseguire spostamenti da 0 a 15 a destra e da 1 a 16 a sinistra in 5 fasi o livelli.
- Prima lo spostatore controlla se è richiesto uno spostamento logico o aritmetico e seleziona appropriatamente 0 o il bit di segno dell'operando per poi aggiungerlo per l'operazione di spostamento a destra.
- Poi lo spostatore controlla il bit più significativo di s, poiché questo bit ha peso negativo.
- Se $s[4] = 1$, viene eseguito uno spostamento a sinistra di 16 e il risultato viene mantenuto come un numero di 31 bit.
- Nel caso in cui $s[4] = 0$, il numero viene esteso appropriatamente a un numero di 31 bit per il livello successivo per eseguire gli spostamenti appropriati.
- Per il resto dei bit, la logica esegue uno spostamento a destra uguale al peso del bit in considerazione, e il progetto continua a ridurre il numero di bit alla larghezza richiesta all'uscita di ogni fase.

![[Pasted image 20240219092018.png]]
##### Applicando il Pipeline
![[Pasted image 20240219092134.png]]
### Moltiplicazione con Barrel Shifter
- Un barrel shifter può anche essere utilizzato come un moltiplicatore dedicato nelle FPGA.
- Uno spostamento per s a sinistra significa una moltiplicazione per 2^s.
- Uno spostamento a destra per s equivale a una moltiplicazione per 2^-s.
- Per eseguire questa operazione, il numero per cui si desidera moltiplicare deve essere una potenza di 2.


## Architetture Dedicate di Filtri FIR
- Possiamo posizionare solo registri all'ingresso e all'uscita del nostro sistema, perché se proviamo a farlo nel mezzo del sistema, si rompe la catena del carry.
### Forma Diretta
Il filtro FIR è molto comune nelle applicazioni di elaborazione del segnale.
Un filtro FIR viene implementato come:
![[Pasted image 20240219182519.png]]
L'implementazione del FIR richiede che tutte queste moltiplicazioni e addizioni vengano eseguite simultaneamente, richiedendo L moltiplicatori e L-1 sommatori.
La moltiplicazione con coefficienti costanti può sfruttare la semplicità del moltiplicatore CSD.
Ognuno di questi moltiplicatori, in molte istanze di progetto, viene ulteriormente semplificato limitando a quattro il numero di cifre CSD diverse da zero in ogni coefficiente.
Una cifra CSD diversa da zero in un coefficiente contribuisce approssimativamente a 20 dB di attenuazione della banda di taglio.
L'attenuazione della banda di taglio è una misura dell'efficacia di un filtro.

![[Pasted image 20240219182622.png|400]]

### Forma Diretta Trasposta

La struttura del filtro FIR in forma diretta risulta in una grande nuvola combinazionale di albero di riduzione e CPA.
Il percorso critico consiste in un moltiplicatore e un sommatore.
L'aggiunta del pipelining per ridurre il percorso critico causa latenza e un grande sovraccarico di area nell'implementazione dei registri.
Il retiming è una tecnica efficace per spostare sistematicamente i ritardi algoritmici in un progetto per ridurre il percorso critico del circuito logico.
La tecnica del retiming viene applicata per trasformare il filtro FIR diretto in trasposto.
È interessante osservare che in questo modo, senza aggiungere registri di pipelining, i ritardi dell'algoritmo vengono spostati sistematicamente utilizzando la trasformazione del retiming dal bordo superiore del DFG al bordo inferiore.

![[Pasted image 20240219183519.png|400]] ![[Pasted image 20240219183521.png|400]] ![[Pasted image 20240219183522.png|400]]

## Aritmetica Distribuita 
- L'aritmetica distribuita (DA) è un altro modo per implementare un prodotto punto dove una delle matrici ha elementi costanti.
- Il DA può essere utilizzato in modo efficace per implementare algoritmi di tipo FIR, IIR e FFT.
- La logica DA sostituisce l'operazione MAC della somma di convoluzione in una lettura di tabella di ricerca in serie di bit e operazione di addizione.
- Considerando l'architettura delle FPGA, i progetti efficaci tempo/area possono essere implementati usando tecniche DA.
- La logica DA funziona espandendo prima la matrice di numeri variabili nel prodotto punto come un numero binario e poi riorganizzando i termini di MAC rispetto al peso dei bit.
![[Pasted image 20240219183720.png|100]]
- Dove K, Ak e xk è la lunghezza di entrambe le matrici, gli elementi di una matrice di costanti e variabili, rispettivamente.
![[Pasted image 20240219183831.png|400]] ![[Pasted image 20240219183835.png|400]] ![[Pasted image 20240219183838.png|400]] ![[Pasted image 20240219183840.png|400]] ![[Pasted image 20240219183841.png|400]] ![[Pasted image 20240219183842.png|400]]



# Uni

## Moltiplicatore

- Il ritardo di un moltiplicatore base è di $3N-2$
  - Per un numero molto alto di bit si può approssimare a 3N.

### Struttura Matriciale Ottimizzata

![[Pasted image 20231106095948.png|600]]

- Il ritardo è di N+VMA.

### Moltiplicazione e Somma

- Chiamata anche MACC (moltiplicazione e accumulatore).
- Stiamo eseguendo l'operazione di $$Y=AxB+C$$
- Dove A e B sono di 3 bit e C di 6 bit.
- Per eseguire questa operazione al blocco di moltiplicazione ottimizzato, a ciascun primo blocco di ogni colonna viene assegnato come ingresso del carry il valore corrispondente di C.

![[Pasted image 20231106102702.png|500]]

- Con questo blocco possiamo anche eseguire la convoluzione aggiungendo semplicemente un registro all'uscita del blocco e che questo sia l'ingresso della somma e che gli ingressi della moltiplicazione siano quelli corrispondenti.
- Con questo stesso blocco possiamo implementare il blocco per eseguire la somma di numeri in complemento a 2.

### Moltiplicatore WALLACE

Per vedere questa modifica analizziamo un moltiplicatore di 4 bit:

![[Pasted image 20231106110610.png|900]]

- Cambiamo la struttura di sinistra con quella di destra per risparmiare un sommatore e 2 tempi di ritardo.
- Fondamentalmente si usa un compressore 10→4.
- Questa struttura si chiama **WALLACE**.



---
---
---
----
----

# Proc. Emb. y Unid. aritméticas en FPGAs

## Introduccion
- Las FPGAs han surgido como dispositivos que permiten desarrollar aplicaciones de procesamiento de señales de alto rendimiento.
	- Han superado a la tradicional tecnología de procesadores de señal DSP.
	- En la actualidad, los FPGA cuentan con procesadores incorporados, interfaces estándar y bloques de procesamiento de señales constituidos por multiplicadores, sumadores, registros y multiplexores.


## Herramientas para el diseño de unidades aritmeticas en FPGA
- El usuario puede configurar distintas opciones de síntesis para el diseño. Las herramientas cuentan con bloques básicos de construcción. 
	- En casos en donde se tienen operaciones de orden superior, la herramienta hará múltiples copias y combinaciones de estos bloques básicos para lograr la funcionalidad deseada.
	- Por ejemplo si se diseña un multiplicador de 32 bits por 32 bits, la herramienta colocará cuatro multiplicadores de 18 bits por 18 bits para lograr satisfacer el diseño deseado.
![[Pasted image 20240218182506.png]]


- El usuario también podrá instanciar estos bloques básicos de forma explícita si el diseño así lo requiriera.
- El fabricante provee en la herramienta de diseño plantillas que contienen estos bloques para que puedan se utilizados por el diseñador.
- Estos bloques básicos son bloques embebidos en el dispositivo.
- En caso que el FPGA se quedara sin recursos embebidos construirá los bloques utilizando componentes de lógica genérica contenidos en el dispositivo FPGA.
- Estos bloques generados funcionan con menos eficiencia que los bloques embebidos.
- Estos recursos embebidos han generado un gran salto en el rendimiento de las implementaciones.
### Comparacion de recursos usados con y sin DSP
- Se implemento un filtro IIR de segundo orden en una Spartan 3 y una Virtex 4
	- La primera no cuenta con DSP pero si tiene bloques de multiplicadores embebidos de 18 bits
	- La virtex cuenta con DSP 48
![[Pasted image 20240218183226.png|400]]![[Pasted image 20240218183235.png|400]]![[Pasted image 20240218183228.png|300]]



# Sumadores
## Introduccion
- Los bloques aritmeticos de un sistema son esencial, en principal los sumadores, ya que etos se utilizan en adicion, substraccion, mutiplicacion y division.
- Para una suma de 2 operandos de Nbits, su representacion a la salida sera N+1bits
- *Por que hay tantos tipos de sumadores?* Porque se busca manipular de la mejor forma posible el carry


### Sumadores basicos
#### Half Adders
Circuito combinacional usado para sumar 2 bits $a_i$ e $b_i$, sin un acarreo de entrada$$s_i=a_i \bigoplus  b_i$$$$c_i=a_ib_i$$
#### Full adders
Un sumador de 3bits, tambien llamado compresor 3 a 2. $$s_i=a_i\bigoplus b_i\bigoplus c_i$$$$c_{i+1}=(a_i\bigoplus b_i)c_i\bigoplus a_ib_i$$
- Estas estructuras se plantean de manera diferentes dependiendo la herramienta y el hardware
	- En FPGA se pueden usar LUT por ejemplo
##### Ejemplos de implementacion full adders
![[Pasted image 20231108112100.png|400]]
 



### Distintos tipos de sumadores de N bits
- **Ripple-Carry(RCA):** Son los mas lentos de la familia de sumadores, implementan el modo tradicional de suma entr 2 numeros, se espera a que se genere el acarreo luego de la suma, su lado positivo es su simplicidad, que permite en menor numero de compuertas
- **Look-ahead-adder:** Sumadores rapidos, con propagacion de acarreo mas rapido y eficiente, se logra que estos se generen simultaneamente por una logica generadora de acarreo, esto permite realizar suma en paralelo sin tener que esperar la propagacion del mismo
- **Carry Select Adder(CSA):** Particiona la suma en K grupos, para ganar velocidad la logica es replicada y para cada grupo la suma asume acarreo de entrada(0 o 1). Cuando se obtiene un acarreo este selecciona el siguiente bloque dependiendo su valor y asi sucesivamente.
- **Sumador de suma condicional:** Como un CSA con el maximo numero posible de niveles. La operación de selección de acarreo en el primer nivel es realizada por grupos de 1 bit. En el  siguiente nivel dos grupos adyacentes se fusionan para dar el resultado de una operación de  selección de acarreo de 2 bits. Está fusión de dos grupos es repetida hasta que los últimos dos grupos se fusionan para generar la suma final y el acarreo de salida. Es el mas rapido de toda la familia
### Ripple carry adders(RCA)
- Considerado como el sumador mas lento
	- Son los bloques basicos de suma en una FPGA(son los mas ideales) ya que puede utilizar la cadena de acarreo.
	- Usa un area minima y una estructura regular
	- No se debe usar en ASIC si buscamos velocidad
- Si suma 2 operandos de Nbits necesita Nfull adders
![[Pasted image 20231108112410.png|400]]
- Retardo: $T_{RCA}=(N-1)T_{FA}+ T_M$
- Donde TRCA es el retardo del RCA, TFA es el retardo del FA y Tm es la lógica de generación del acarreo.
	- Si nuestra logica de acarreo es otro FA, la demora es N.TFA
#### Codigo de implementacion
![[Pasted image 20240218194101.png]]
#### Implementacion en FPGA
![[Pasted image 20240218194629.png]]
- Tenemos que buscar que se use la cadena de acarreo cuando usamos esta arquitectura
## Sumadores Rapidos

### Block Generate e Block Propagate
- Para la suma, no es siempre necesario calcular el acarreo
![[Pasted image 20231108121439.png]]
Entonces →$Cout=A.B+(A\bigoplus B)Cin$
- Cuando aplicamos esto para varios bits, nos queda como: $$Ci+1=G_i+P_iG_{i-1}+P_iP_{i-1}G_{g-2}+...+P_iP_{i-1}...P_0C_{in}$$
- Esto se puede escribir como: $$C_{i+1}=BGi+BPi.C_{in}$$
- Donde el **BG es el block generate(AND) y BP es el block propagado(XOR)**, este ultimo es igual a la productoria de P del ultimo termino de la sumatoria
- Esto nos indica que si $a_i=b_i=1$ el $c_{i+1}$ es generado, pero si solo alguno de los 2 es 1, entonces es propagado
### Carry Skip Adder/Carry Bypass Adder
- En un carry skip adder de N bits, estos bits son divididos en grupos de k bits.
- El sumador propaga todos los acarreos en forma simultánea a través de estos grupos.
- Si cada grupo genera acarreo, lo pasa al siguiente grupo.
- En caso que el grupo no genere acarreo debido a la distribución de los bits en el bloque, entonces simplemente transfiere el acarreo del grupo anterior al grupo siguiente (bypass del acarreo).
- Este bypass del acarreo es manejado por Pi .
- Calculamos el Pi y este en un multiplexor decide si necesitamos el carry generado o podemos usar el propagado
![[Pasted image 20240218202443.png]]
![[Pasted image 20231108124143.png]]
- Una ventaja de esta estructura es que si BP del ultimo bloque es 0, podemos tomar el acarreo generado localmente sin necesidad de esperar el propagado
##### Analisis temporal dependiendo el valor de Pi
![[Pasted image 20231108124356.png]]
- La mejor condicion es la 1,1,1
- La peor es 1,1,0
- Analizaremos la peor, la cual genericamente es $$tp=mt_{a}+pt_{mux}$$
- La expresion es muy similar a la calculada en el Carry Select Adder, lo que nos deja como resultado $$p=\sqrt{\frac{Nt_a}{t_{mux}}}$$
$$tp=2\sqrt{Nt_{a}t_{mux}}\approx\sqrt{N}$$
- A pesar de ser mayor al **Carry Select Adder** no nos olvidemos que estamos comparando el peor caso y este es mucho mas compacto que el CSA.
#### Sistema mas optimizado
- Para realizar un bloque de propragacion de 4 bits, necesitamos 4 XOR y 4 AND
- Para encontrar el bloque mas optimizado con esta arquitectura debemos
	- Igualar los retrasos del Carry tanto en la generacion como en la progacion para cada bloque
	- Igualar los retrasos en las operaciones de suma en todos los bloques, de manera que los bits de suma se generen idealmente simultaneamente en todos los bloques
- Cuando analizamos la demora del BP en un bloque de i bits, nos damos cuenta que la demora crece de manera lineal con i $$L(i)=(i-1)\frac{t_{mmux}}{t_a}+L(0)$$
- Cuando analizamos la demora de la suma, nos damos cuenta que es la misma expresion solo, que con una relacion decreciente $$L(i)=(p-i)\frac{t_{mmux}}{t_a}+L(p)$$
- La solucion optima es bloque centrales mas largos y bloques extremos mas cortos
![[Pasted image 20231108130345.png]]

### Carry Look-Ahead Adder(CLA)
- Haciendo un análisis más profundo de la generación de acarreo(**Block Generate y Block Propagate**) se puede llegar a que la misma no tiene que depender de los acarreos anteriores.
- En un carry look-ahead adder (CLA) el acarreo de los bits de todas las posiciones del sumador es generado en forma simultánea. Esto significa, que el cálculo del acarreo se realiza en paralelo al cálculo de la suma.
- *Esto genera que el tiempo que demora la suma en ejecutarse sea independiente de la longitud del sumador.*
- No obstante, a medida que *el tamaño de palabra aumenta* la distribución del hardware para realizar la adición se *hace más compleja*.
	- Es por esto que solo se emplean CLA de hasta 4 entradas.
	- Esto nos lleva a que para los sumadores de un gran tamaño sea necesario utilizar dos o tres niveles de bloques CLA.

#### CLA para 4 bits
##### CLA:Nivel compuertas
![[Pasted image 20231108122450.png|500]]


##### CLA:Nivel transistores
Se puede usar una compuerta AND-OR-INVERT para implementarlo
- Esta estructura se llama **Machester Carry Chain**
![[Pasted image 20231108133913.png]]
#### Suma de 4 bits con CLA
- Implementando compeurtas XOR se puede obtener la suma con  el mismo circuito
![[Pasted image 20231108132033.png]]
- El retardo es: $t_p=t_{G.P}+t_{xor}+3.t_{CLA}$

#### Suma de 16 bits con CLA 
- Tiene una escala logaritmica en tiempos, relacionado con el numero de bits involucrados
- En los bloques CLA(Carry Look Ahead) *no se utilizan directamente las entradas, mas bien se utilizan bloques G.P que hacen la XOR y la AND *
- Para calcular la suma es necesario retroalimenta los carry en la entrada de los diferente bloques, como Cin, C4, C8, C12
![[Pasted image 20231108131316.png|500]]
- Este metodo de suma no es muy eficiente para valores bajos de suma, debe usarse para summas a partir de 16 bits
- A nivel FPGA:
	- N>64 C look ahead
	- N<64 C skip adder
##### Sistema de DDA
![[Pasted image 20231108154106.png|500]]
#### Suma de 32 bits con CLA

![[Pasted image 20231108132533.png|500]]
- Retardo: $t_p=t_{G.P}+t_{xor}+(2k-1)t_{CLA}\approx log_{2}(N)-1$

### Bren-Kung Adder
- Caso especial de Look Ahead
- Usa el concepto del binary
Se usa una operacion que goza de la propiedad associativa para calcular el carry, la cual es la siguiente:
![[Pasted image 20231109082233.png|300]]
A continuacion podemos vercomo respeta la propiedad asociativa y como nos sirve:
![[Pasted image 20231109082311.png]]
- **Suma de 8 bits con bloques Bren-Kung Adder**
![[Pasted image 20231109082925.png]]
- **Obtencion de los restos con bloque Bren-Kung Adder**
![[Pasted image 20231109083023.png]]
- Podemos ver que la suma y la obtencion de los restos se realizan en solo 3t, lo cual es una enorme ventaja, la ecuacion generica es: $$t_p\approx log_2(N)$$
- La desventaja de esta celdas en la cantidad de interconexiones
- Las ventajas son su regularidad y su tiempo



### Carry Select Adder(CSA) 
- Éste particiona la suma en K grupos, para ganar velocidad la lógica es replicada y para cada grupo la suma asume acarreo de entrada (el cual puede ser 0 o 1).
	- La suma y acarreo de salida correctos para cada grupo son seleccionados por el acarreo de salida del grupo previo. El acarreo de salida seleccionado, a su vez, es utilizado para seleccionar la suma y acarreo de salida correctos del siguiente grupo adyacente.
	- Para sumar número grandes se utilizan CSA jerárquicos, los cuales dividen la suma en múltiples niveles.
- Un conjunto de sumadores calcula la suma suponiendo un acarreo de entrada igual a 1 y el otro un acarreo de entrada igual a 0
- La suma real y el acarreo se seleccion usando un mux basado en el acarreo del grupo anterior
- Este es mas lento que Carry Look-Ahead Adder pero es ideal para FPGA
![[Pasted image 20231108120802.png|500]]
- De esta manera el retraso total sera el retraso de un bloque + en retardo del numero de multiple\bigoplus es que haya
#### CSA de varias etapas
![[Pasted image 20231108120946.png|500]]
- El CSA se puede dividir en varias etapas
- En la figura se divide en grupo de N/2 bits que a su vez se divide en N/4 bits
- Si se dividieran los grupos hasta llegar a subgrupos de 1bit cada uno, la arquitectura del sumador seria la misma del conditional sum adder por lo que consideramos a este un caso partiular de CSA
#### Buscando el conjunto ideal de sumadores para mayor velocidad
- Tenemos que el numero de bits sumados son $N=m.p$
- Ademas sabemos que $t_{total}=m.t_0+(p-1).tmux$
	- Donde p es el numero de bloques
	- m es el numero de sumas por bloque
- Para encontrar el valor minimo que se puede tener de retraso, derivamos e igualamos a 0, con esto encontramos que $$t_{total,min}=2\sqrt{N.t_0.t_{mux}}-t_{mux}$$
- Donde $$p= \sqrt{\frac{N.t_0}{t_{mux}}}$$



### Sumador condicional
- Este sumador es implementado en múltiples niveles.
	-  Puede ser considerado como un CSA con el máximo número posible de niveles.
- La operación de selección de acarreo en el primer nivel es realizada por grupos de 1 bit. En el siguiente nivel dos grupos adyacentes se fusionan para dar el resultado de una operación de selección de acarreo de 2 bits. Está fusión de dos grupos es repetida hasta que los últimos dos grupos se fusionan para generar la suma final y el acarreo de salida.
- Este sumador es el más rápido de la familia.
	- El problema es si se implementa bien
![[Pasted image 20240218204720.png|500]]![[Pasted image 20240218202549.png|200]]

- En el nivel dos, los resultados del nivel uno se fusionan. Esa fusión se realiza a través del emparejamiento de las columnas consecutivas del nivel 1. Para un sumador de N bits, las columnas son emparejadas de la forma $( i, i+1)$ para i que va desde 0 hasta N-2.
- Los bits menos significativos del acarreo (LSC) en una determinada posición i de cada par seleccionan los bits de suma y de acarreo de la posición i+1 para el siguiente nivel de procesamiento.
- Si el least significant carry LSC está en 0 los bits calculados para el acarreo de entrada 0 serán seleccionados, en caso contrario se seleccionarán los bits correspondientes al acarreo de entrada 1.
- De esta manera dos bits serán sumados asumiendo un determinado valor para el acarreo de entrada.
- Permite implementar pipeline
#### Ejemplo de 3 bits

![[Pasted image 20240218202614.png]]

- En el ejemplo anterior podemos ver el sumador CSA sumando números de 3 bits.
- En el primer nivel cada grupo consiste de un bit. El nivel añade los bits de la posición i suponiendo el acarreo de entrada en 0 y en 1.
- En el siguiente nivel las tres columnas se dividen en dos grupos (como muestra la línea punteada). La columna en la posición del bit 0 forma el primer grupo y las otras dos columnas el segundo grupo. La selección apropiada en cada grupo por parte del LSC se muestra con la línea diagonal.
- El LSC de cada grupo determina cual de los dos bits de la siguiente columna se reducirá al siguiente nivel de tratamiento.
- Si el LSC es 0 se seleccionan los bits superiores de la siguiente columna, de lo contrario se seleccionan los dos bits inferiores de la siguiente columna.
- Para el segundo grupo el bit de suma de la primer columna también baja al segundo nivel. Los LSC en el primer nivel esta resaltados en el gráfico en negrita.
- Finalmente en el siguiente nivel los dos grupos formados en el nivel anterior se combinan y el LSC selecciona uno de los dos grupos de 3 bits para pasar al siguiente nivel. Como el LSC es 1, selecciona el grupo inferior.

#### Ejemplo N bits
![[Pasted image 20240218210102.png]]


### Otros sumadores interesantes
#### Hybrid Ripple Carry y Carry Look-Ahead Adder
- En lugar de construir un gran sumador CLA usando múltiples niveles jerárquicos de lógica CLA, el acarreo puede simplemente propagarse entre los bloques.
- Este tipo de sumador será más rápido que un RCA y ocupará menos área que un sumador jerárquico CLA.
- Esto es debido a que tenemos un sólo nivel de lógica CLA.
![[Pasted image 20240218201630.png]]

#### Bynary Carry Look- Ahead Adder(BCLA)
- Un BCLA trabaja con un grupo de dos bits adyacentes, desde el LSB hasta el MSB combinando los bits en grupos de a dos para formar un nuevo grupo de bits y su correspondiente acarreo.

![[Pasted image 20240218201917.png|300]]

- Hay muchos caminos para implementar estas ecuaciones. El objetivo es realizar esta implementación para cada posición de bit moviéndose desde los LSB a los MSB, esto requerirá una sucesiva aplicación del operador * en las posiciones de dos bits adyacentes.
- Para un sumador de N bits serán necesarios N-1 etapas de implementación de los operadores.



















## Sumadores Carry Save y Compresores
- En lugar de realizar la suma binaria directamente como lo hace un Full Adder, un CSA opera en dos etapas: *generación de sumandos parciales y propagación de acarreos*.
- En la etapa de *generación de sumandos parciales*, los bits de los operandos *se suman sin tener en cuenta los acarreos*. *Esto produce dos resultados: la suma de los bits de datos (S) y una representación en exceso-3 de la suma de los bits de datos (G).*
- En la etapa de *propagación de acarreos*, los *bits de acarreo se calculan a partir de las sumas parciales generadas* en la etapa anterior.
- Cuando un CSA reduce tres operandos a dos, *no propaga el acarreo*. Más bien *guarda el acarreo en la siguiente posición de bit significativo*. Esto significa que la adición reducirá tres operandos a dos sin tener un retardo por propagación de acarreo.
- A este sumador, por su forma de operar, también se lo denomina compresor 3:2. A diferencia del full adders, *este compresor de 3 a 2 esta asociado a palabras y no a bits*
![[Pasted image 20240219092650.png]]
**Observaciones:**
- La ventaja principal de un CSA es su capacidad para sumar múltiples operandos en paralelo sin generar acarreos en cada etapa, lo que lo hace más rápido que otros tipos de sumadores para ciertas aplicaciones, como multiplicadores y sumadores de alta velocidad.
- En cuanto a timing y área, el CSA es uno de los sumadores más eficientes y utilizados para acelerar los diseños digitales de sistemas de procesamiento de señales que se ocupan de múltiples operandos para la adición y la multiplicación.
- Hay muchas técnicas que utilizan CSA para sumar más de tres operandos. Estas técnicas son muy utilizadas para reducir los productos parciales en el diseño de multiplicadores.




### Notacion de puntos
- La notación de puntos se utiliza para explicar diferentes técnicas de reducción.
- En esta notación cada bit en la suma de dos operandos está representado por un punto.
- Una técnica de reducción 3:2 reduce tres capas de productos parciales a dos.
![[Pasted image 20240219094109.png]]
#### Manejo de puntos
- Esta técnica considera el número de puntos en cada columna, en caso que aparezca un punto aislado en una columna simplemente se reduce al siguiente nivel de lógica.
- Cuando se tienen dos puntos en una sola columna se agregan usando un half adder, el punto para la suma se deja caer en la misma columna y el punto para el acarreo se coloca en la siguiente columna significativa. El uso de un half adder para esta operación también se conoce como reducción 2:2.
- Los tres puntos en una columna se reducen a dos utilizando un full adder. En este caso, el punto para la suma se coloca en la misma ubicación de bit y el punto para el acarreo se coloca en la siguiente posición de bit significativo.
![[Pasted image 20240219094125.png]]

### Compresores de mayor orden
- Basándose en el concepto de CSA, pueden desarrollarse otros bloques de compresores.
- Comprimiendo múltiples operandos el compresor trabaja en cascada.
- Si se implementan estos compresores utilizando la lógica de cadena de acarreo se pueden obtener mejores resultados de timing y de área que utilizando CSA.
- Las sumas multi operando en ASIC (circuito integrado de aplicación específica) son generalmente implementados usando CSA basados en arboles de reducción Wallace y Dadda.
- Con LUTs y cadenas de acarreo en la FPGA, la implementación de un contador ofrece una mejor alternativa a la suma de múltiples operandos basados en CSA.
	- Estos contadores añaden todos los bits en una o varias columnas para utilizar mejor los recursos de FPGA.


#### Ejemplos

![[Pasted image 20240219103551.png]]
- Cada LUT calcula la suma respectiva, bits de carry0 y carry1 del compresor.
- También se pueden construir contadores de diferentes dimensiones, y una mezcla de éstos se puede utilizar para reducir varios operandos a dos.
- En la siguiente figura se pueden ver contadores 15:4, 4:3 y 3:2 que trabajan en cascada para comprimir una matriz 15 x 15.

![[Pasted image 20240219103617.png]]

#### GPC
![[Pasted image 20240219103636.png]]
![[Pasted image 20240219103648.png]]

GPC ofrece flexibilidad una vez asignada a una FPGA.
El problema de configurar dimensiones de GPC para mapear en FPGA para la suma de múltiples operandos, es un problema completo - NP.
El problema se resuelve con la "programación entera", y se informa que el método supera a la aplicación basada en árboles sumadores desde el área y las perspectivas de tiempo.
Las FPGAs son las más adecuadas para los contadores y los árboles de compresión basados en GPC.
Para utilizar completamente las FPGAs basadas en 6- LUT, es mejor que cada contador o GPC tenga 6 bits de entrada y 3 (o 4 mejor) bits de salida, como se ve en las siguientes
imágenes.
Los cuatro bits de salida son favorecidos como los LUTs en muchos FPGAs vienen en grupos de dos con entrada de 6 bits compartida, y un 6: 3 GPC desperdiciaría un LUT en cada compresor, como se muestra en la en la segunda imagen.
![[Pasted image 20240219103704.png]]
![[Pasted image 20240219103716.png]]






### Reducción del Árbol de Suma
- Aunque varios dispositivos de las familias de las FPGA ofrecen multiplicadores embebidos, los árboles compresores todavía son críticos en muchas aplicaciones.
- El árbol de compresión es el primer bloque de construcción en reducir los requerimientos del número de CPAs para la suma de múltiples operadores.
**Ejemplo:**
- En el siguiente ejemplo, se agregan 5 operadores signados en los formatos S(6.5), S(8.3), S(11.7) y S(12.6).
- La lógica de extensión de signo que se construye primero, se elimina mediante el cálculo de un vector de corrección y se agrega como la sexta capa en representación de puntos.
- En la figura se muestra que la colocación de los puntos en una cuadrícula, requiere un árbol de compresión para reducir el número de puntos en cada columna a 2. Esto se puede demostrar utilizando cualquier técnica de reducción. Aquí emplearemos la reducción de Dadda.
- Luego, los dos operandos se introducen en un CPA para la suma final.


![[Pasted image 20240219121007.png]]



### Trasformaciones de Algoritmos para CSA
- El CSA desempeña un papel importante en la implementación de aplicaciones DSP de alto rendimiento en hardware.
- Mientras se asigna un gráfico de flujo de datos a la arquitectura, se observa que el gráfico muestra cualquier uso potencia de CSA y, en consecuencia, el gráfico se modifica.

**Ejemplo basico**
- Por ejemplo, considere implementar las siguientes ecuaciones:
	- $d[n] = a[n]+b[n]+c[n]$
	- $y[n] = d[n-1] \cdot e[n]$
- Las ecuaciones son convertidas a DFG en la figura (a).
- Esto se modifica usando CSA para comprimir $a[n]+b[n]+c[n]$ en dos números, que luego se suman usando un CPA. Éste DFG transformado se muestra en la figura (b).

![[Pasted image 20240219121025.png|300]] 
![[Pasted image 20240219122713.png|300]]

#### Transformaciones para sumas
- Ésta técnica de extracción de suma de múltiples operandos puede extenderse a gráficos de flujo de datos, donde se observa que los gráficos muestran cualquier uso potencial de CSA y árboles compresores.
- Los gráficos se transforman primero para utilizar óptimamente los árboles compresores y luego se mapean en hardware.
- Éstas transformaciones han demostrado mejorar significativamente el diseño de hardware de las aplicaciones de procesamiento de señales.
- Las operaciones de suma múltiple son las más fáciles de todas las transformaciones.
![[Pasted image 20240219121059.png]]
![[Pasted image 20240219121109.png]]

#### Transformaciones para operacion de sumar y multiplicar
- De forma similar a la anterior, la siguiente operación de sumar y multiplicar se puede representar con su equivalente DFG: $op1 \cdot (op2+op3)$
- El DFG puede ser transformado para usar eficazmente un árbol compresor.
- Una implementación directa requiere un CPA para realizar op2+op3, y luego el resultado de esta operación es multiplicado por op1.
- La arquitectura de un multiplicador comprende un árbol compresor y un CPA.
- Para implementar el cálculo, se requieren 2 CPA.
- Una transformación simple utiliza la propiedad distributiva del operador de multiplicación:
	- $op1 \cdot op2+op1 \cdot op3$
- Esta representación de la expresión ahora requiere un árbol de compresión, que luego es seguido por un CPA para calcular el valor final.
- El DFG asociado y la transformación se ven en la siguiente figura.

![[Pasted image 20240219121126.png]]

#### Transformaciones para cascada de multiplicaciones
- Ampliar la técnica de generar sumas parciales y acarreo, también puede optimizar la implementación de una cascada de multiplicaciones: $prod = op1 \cdot op2 \cdot op3 \cdot op4$
- La transformación primero genera PPs para $op1 \cdot op2$ y los reduce a los PPs, s1 y c1: $(s1;c1) = op1 \cdot op2$
- Estos 2 PPs se multiplican independientemente con op3, generando 2 conjuntos PPs que se reducen de nuevo a 2 PPs, s2 y c2, usando un árbol de compresión: $(s2,c2) = s1 \cdot op3+c1 \cdot op3$
- Estos dos PPs se multiplican con op4 para generar 2 conjuntos de PPs que se comprimen de nuevo para calcular 2 PPs finales, s3 y c3. Estos dos PPs se agregan a continuación usando un CPA para calcular el producto final: $(s3,c3) = s2 \cdot op4+c2 \cdot op4$    …..     $prod = s3+c3$
- Esto se ilustra en la siguiente imagen.
![[Pasted image 20240219123736.png]]
## Suma UNISA
### Implementando la resta con el circuito de la suma
- Primero debemos cambiar la resta por una suma $$A-B=A+(-B)$$
- Y si tenemos el negado con complemento a 2, de esta manera ya se aplicaria la resta
- Para poder invertir una entrada cuando sea resta, se usa un multiplexor para seleccionar el carry de entrada 
![[Pasted image 20231027143231.png|400]]



### Sumador de 4 numeros de 4 bits

![[Pasted image 20231106090059.png|500]]
- Cuando hacemos una suma de 2numeros de 4 bits necesitamos un numero de 5 bits para el resultado
	- En este caso como estamos haciendo una suma de 4 numeros de 4 bits pensariamos que necesitamos 7 bits por la estructura, pero no es asi
		- Ya que la suma de 2 numeros de puede dar 32 posbilidades de 3, 48 y de 4 64bits
		- Entonces solo necesitamos 6, por lo que el ultimo bit sera siempre 0
### Sumador de 4 numeros de 4 bits optimizado en velocidad 
- Nos damos cuenta que no hace falta que al resto de cada suma lo mandemos a sumar en el siguiente sumador
	- Por ejemplo, el resto de la suma de a0 y b0 se podria sumar con a1 y b1 o tambien con d1, entonces podemos simplificar el sistema
![[Pasted image 20231106091127.png|500]]
- Esta estructura se llama carry save, y reduce el retardo de 8t a 6t
- Tambien hay que tener en cuenta que agregamos el bloque VMA al final
	- VMA(vector multiplicador addres)
	- Este bloque realiza la suma con mas superficie de silicio pero mucho mas rapido
### Sumador optimizado al maximo en recursos
- Si quiero simplificar al maximo la estructura usada sin importar la demora para poder sumar una cantidad de n bits, podemos hacer uso de pipeline para solo usar 1 bloque sumador de 1 bit
![[Pasted image 20231106092758.png]]

# Multiplicadores
## Multiplicadores Paralelos
- Los diseñadores de sistemas de alto rendimiento se interesan por desarrollar multiplicadores que calculen el producto en un sólo ciclo.
	- Para lograr esto se diseñan arquitecturas de multiplicadores paralelos.
	- Un CSA es un bloque fundamental en estas arquitecturas.
- Los productos parciales se reducen primero a dos números utilizando un árbol CSA.
- Estos dos números son luego sumados para obtener el producto final.
- En la actualidad las FPGAs poseen un gran número de sumadores dedicados. Estos sumadores pueden sumar tres operandos. Los árboles reductores pueden reducir el número de productos parciales a tres en lugar de dos para hacer uso completo de estos bloques.
- Cualquier arquitectura *multiplicadora paralela consta de tres operaciones* básicas: 
	1. Generación de producto parcial
	2. Reducción del producto parcial
	3. Cálculo de la suma final usando un CPA (Carry Propagation Adder).


![[Pasted image 20240219094303.png]]

### Generación de Productos Parciales
- Mientras se multiplican dos números de N bits a y b, se generan los productos parciales.
- Los mismos se pueden generar ya sea utilizando el *método de ANDing* o implementando un algoritmo de *recodificación de Booth*.

#### Metodo ANDing
- Genera un producto parcial PPi a través de una operación AND de cada bit ai del multiplicador con todos los bits del multiplicando b.
- Cada PPi es desplazado a la izquierda i posiciones antes de que los productos parciales sean sumados por columnas para producir el resultado final.
![[Pasted image 20240219094717.png]]




#### Multiplicador de Booth
- Reducir el número de productos parciales es una técnica de optimización que se utiliza en muchos diseños.
- El multiplicador modificado de Booth (MBR) es una de estas técnicas.
- Cuando multiplicamos dos números de N bits signados a y b, la técnica genera un producto parcial por cada uno a través del emparejamiento de todos los bits de b en grupos de dos bits.
- La técnica, al pasar del LSB al MSB de b, empareja dos bits juntos para hacer un grupo que será recodificado usando el algoritmo MBR.
- Los dos bits de un grupo pueden ser 00, 01, 10, 11 (binarios).
- La multiplicación por 00, 01 y 10 simplemente resultan en 0, a y 2a = a << 1 respectivamente, donde cada producto parcial es calculado como un número.
- La cuarta posibilidad es 11 binario que es igual a 3 decimal, igual a 2 + 1, y un simple corrimiento podría no generar el producto parcial requerido. Esta multiplicación dará como resultado dos productos parciales que son a y 2a. Esto significa que en el peor caso el multiplicador tendrá N productos parciales.




- El problema del caso 11 para generar dos productos parciales es resuelto usando el algoritmo de recodificación de Booth.
- Este algoritmo trabaja con grupos de dos bits pero recodifica cada grupo para usar uno de los cinco valores equivalentes: 0, 1, 2, -1, -2. La multiplicación por todos estos dígitos resulta en un producto parcial por cada uno.
- Estos valores equivalentes son codificados indexándolos en una LUT. Esta LUT es calculada utilizando la propiedad de cadena de números vista anteriormente.
- Esta propiedad es observada en cada par de bits desde del LSB al MSB.
- Para comprobar la propiedad de cadena, es requerido también el MSB del par anterior junto con los dos bits del par bajo consideración. Para el primer par se añade un cero a la derecha.
- La Tabla siguiente muestra la propiedad de cadena trabajando con todos los números posibles de 3 bits para generar una tabla que es luego usada para recodificar.
![[Pasted image 20240219115601.png]]

##### Ejemplo
- En este ejemplo se multiplican dos números de 8 bits 10101101 y 10001101 usando la técnica antes descripta.
- La técnica primero separa los bits en el multiplicador en grupos de dos bits. Luego el MSB del grupo anterior recodifica cada grupo usando la tabla previa. Se supone un cero para el MSB del grupo menos significativo ya que no tiene grupo anterior.
- Los 8 grupos con el MSB del grupo anterior son:
	- 100001110010
- Se observa en la tabla que los números son recodificados a -2, 1, -1 y 1 y los cuatro productos parciales son generados como se verá en la próxima imagen.
- Para un dígito 1 recodificado en el multiplicador, el multiplicando es simplemente copiado.
- Como cada producto parcial es generado de un par de 2 bits del multiplicador, el i producto parcial es desplazado 2i posiciones hacia la izquierda.
- Para el segundo dígito recodificado del multiplicador que es -1, el complemento a 2 del multiplicando es copiado.
- Los productos parciales son generados para todos los dígitos recodificados, para el ultimo dígito de -2 el complemento a 2 del producto parcial es desplazado más a la izquierda una posición de bit para realizar la multiplicación por dos.
- Se extiende el signo de los cuatro productos parciales y luego son sumados para obtener el producto final.
- La lógica de eliminación de extensión de signo podría usarse para reducir la lógica de implementación de hardware.

![[Pasted image 20240219120020.png]]


##### Deduccion matematica del Multiplicador BOOTH
- Este multiplicador hace uso de barrel shifter para multiplicar
- Reescribiendo un numero nos damos cuenta que lo podemos hace en funcion de parametros Ci y de barrel shifter
![[Pasted image 20231106112127.png|1000]]
- En esta deduccion de X se peude ver:
	- El $2^4,2^2,2^0$ hacen referencias a como se corre un lugar a la izquierda y como se deja uno en 0 a la hora de hacer los productos ![[Pasted image 20240722115812.png|90]]
	- Los $C_i$ se obtienen del decodificador

![[Pasted image 20231106112130.png|300]]

##### Multiplicador de booth dinamico
- No tiene mucho sentido con variables porque se necesita mucha logica
![[Pasted image 20240219120112.png]]

##### Multiplicador de booth reutilizando recursos
![[Pasted image 20231106113153.png|500]]





### Reducción de Productos Parciales
- Usando la notación de puntos, todos los productos parciales forman un arreglo de puntos en paralelogramo. Los puntos de cada columna se añadirán para calcular el resultado final.
- En general, para un multiplicador de N1 bits por N2 bits, se utilizan las siguientes cuatro técnicas para reducir N1 capas de productos parciales a dos capas para su adición final usando cualquier CPA:
	- Carry Save Reducción.
	- Dual Carry Save Reducción.
	- Wallace Tree Reduction.
	- Dadda Tree Reduction.
- Las técnicas se describen para compresores 3:2 pero pueden extenderse fácilmente a otros compresores.


#### Carry Save Reduction
- Se reducen las tres primeras capas de los productos parciales usando CSA.
- En las tres capas seleccionadas, los bits aislados en una columna simplemente caen a la misma columna, las columnas con dos bits se reducen a dos bits usando half adders y las columnas con tres bits se reducen a dos bits usando full adders.
- Cuando se suma utilizando las HA y FA, el punto que representa el bit de suma se deja caer en la misma columna mientras que el punto del acarreo se coloca en la siguiente columna de bit más significativo.
- Una vez que los primeros tres productos parciales se reducen a dos capas, el cuarto producto parcial de la composición original se agrupa con las dos capas anteriores para formar un nuevo grupo de tres capas. Estas tres capas se reducen de nuevo a dos utilizando la técnica CSA.
- Este proceso se repite hasta que todo el conjunto se reduce a dos capas de números.
- Como resultado se obtiene unos bits de producto menos significativos, denominados bits de producto libre, y el resto de los bits aparecen en dos capas las cuales se agregan utilizando cualquier CPA.
![[Pasted image 20240219094830.png|400]]
![[Pasted image 20240219094832.png|400]]
#### Dual Carry Save Reduction
- Los productos parciales son divididos en dos grupos de igual tamaño.
- El esquema de Carry Save Reduction es aplicado en ambos sub grupos simultáneamente.
- Como resultado se obtienen dos conjuntos de capas de productos parciales en cada sub grupo.
- La técnica finalmente resulta en cuatro capas de productos parciales.
- Estas capaz son reducidas luego a un grupo de tres y finalmente a un grupo de dos capas.
#### Wallace Tree Reduction
- Los productos parciales son divididos en grupos de tres productos parciales cada uno.
- A diferencia de la reducción de tiempos de los dos métodos anteriores, estos grupos de productos parciales son reducidos simultáneamente usando CSAs.
- Cada capa de CSA comprime tres capas a dos capas. Estas dos capas de cada grupo se reagrupan en conjuntos de tres capas.
- En el siguiente nivel nuevamente se reducen tres capas a dos capas, este proceso continuará hasta que queden solo dos filas.
- Por último cualquier CPA puede utilizarse para calcular el producto final.
- Esta reducción es uno de los esquemas más usados en arquitecturas de multiplicadores.
- La reducción se realiza en paralelo en grupos de tres.
- A medida que el número de productos parciales aumenta, tendremos un incremento logarítmico en el número de niveles del sumador.
- El número de niveles del sumador representa el retardo de la trayectoria crítica.

![[Pasted image 20240219094950.png|400]]
![[Pasted image 20240219095012.png|400]]
- Cada nivel de sumador posee un retardo de FA en su ruta.
![[Pasted image 20240219101705.png]]


#### Dadda Tree Reduction
- Los árboles Dadda requieren el mismo número de niveles de sumador que los árboles Wallace, con lo que el path crítico de timing es el mismo.
	- Minimiza el número de HA y FA en cada nivel de lógica.
- Si se observa la tabla anterior de la reducción deWallace, los límites superiores de la columna de números de productos parciales son los siguientes: 2;3;4;6;9;13;19;28; :::
^1721665184352
- Cada número representa el número máximo de productos parciales en cada nivel que a su vez requiere un número fijo de niveles de sumador.
- La secuencia también muestra que se pueden obtener dos productos parciales a partir de como máximo tres, tres se pueden obtener de cuatro, cuatro de seis y así sucesivamente.
- Dadda Tree Reduction considera cada columna por separado y reduce el número de niveles lógicos de una columna al máximo número de capas en el siguiente nivel.
	- Por ejemplo para reducir un multiplicador de 12.12 bits, la reducción de Wallace reduce de 12 productos a 8 mientras que el esquema Dadda primero los reduce al rango máximo en el siguiente grupo y esto es nueve. Esta acción requerirá el mismo número de niveles de lógica pero resultará en menos hardware.
- En ésta reducción si el número de puntos en una columna es menor que el número máximo de productos parciales que se quiere reducir en el nivel actual, ellos simplemente se pasan al siguiente nivel sin ningún procesamiento.
- Las columnas que tienen más puntos que los puntos requeridos para el siguiente nivel se reducen para tomar las capas máximas en el siguiente nivel.

![[Pasted image 20240219095111.png]]


### Otra estrategia
- Una multiplicación puede ser seccionada en un número de multiplicaciones más pequeñas.
- Por ejemplo, la multiplicación de 16 bits se puede realizar considerando los dos operando a y b como cuatro operandos de 8 bits, tomando los bits más significativos por un lado y los menos por otro obtendríamos aH, aL, bH y bL.
- La descomposición matemática de la operación se da de la siguiente manera:
	- aL = a7a6a5a4a3a2a1a0
	- aH = a15a14a13a12a11a10a9a8
	- bL = b7b6b5b4b3b2b1b0
	- b = b15b14b13b12b11b10b9b8
	- (aL+28aH)x(bL+28bH) = aLxbL+aLxbH28+aHxbL28+aHxbH216
- Se pueden realizar estas cuatro multiplicaciones de 8.8 bits en paralelo para luego obtener el resultado final del multiplicador de 16.16 bits.
![[Pasted image 20240219102957.png]]









## Mult. Signado en Completo a Dos

### Introduccion
![[Pasted image 20240219110420.png]]
- Debido al cambio de i, todos los PPs son números con signos de distinto ancho.
- Todos estos números son necesarios para ser alineados a la izquierda por la lógica de extensión de signo antes de que se agregan para calcular el producto final.
- Como el MSB de a tiene peso negativo, la multiplicación de este bit resulta en un PP que es el complemento de 2 del multiplicando.
![[Pasted image 20240219110511.png]]

- Se extiende el signo de los N1 productos parciales y se suman para obtener el producto final.

#### Ejemplo
- La siguiente figura muestra una multiplicación signada de 4 . 4-bits.
- Los bits de signo de los 3 primeros PPs se extienden y muestran en negrita.
- El complemento a 2 del último PP se toma para satisfacer el peso negativo del MSB del multiplicador.
- Si el multiplicador signado se implementa como en este ejemplo, la lógica de extensión de signo tomará un área significativa del árbol de compresión.
- Se desea eliminar de alguna manera esta lógica del multiplicador.
![[Pasted image 20240219110927.png]]

### Eliminacion de extension de signo
#### Introduccion
- Una observación simple en un número extendido de signos nos lleva a una técnica eficaz para la eliminación de la lógica de extensión de signos.
- Un equivalente del número extendido de signo, se calcula invirtiendo el bit de signo y sumando un 1 en la ubicación del bit de signo, y extendiendo el número con todos los 1s.
- La siguiente imagen explica el cálculo en un número positivo.
![[Pasted image 20240219111609.png]]
#### Vector de correcion
- La herramienta genera este vector de correccion
- En la siguiente imagen se ven los pasos necesarios en la lógica de eliminación de signo de la extensión de signo en un multiplicador signado de 11  6 bit.
- Primero, el MSB de todos los PPs, excepto el último, se da vuelta, suma un 1 en la ubicación del bit de signo, y el número se extiende por todos los 1s.
- Para el último PP, el complemento a 2 se calcula invirtiendo todos los bits y sumando 1 a la posición LSB.
- El MSB del último PP se invierte y suma 1 a esta ubicación de bit para la extensión de signo.
- Todos estos 1s son sumados para obtener un vector de corrección (CV).
- Todos los 1s se quitan, el CV simplemente se suma y se encarga de la lógica de la extensión de signo.
![[Pasted image 20240219111840.png]]

##### Ejemplo
- En el siguiente ejemplo se encuentra el CV para un multiplicador signado de 4x4 bits y se lo usa para multiplicar 2 números: 0011 y 1101.
- En la figura "a" de la siguiente imagen, todos los 1s para la extensión de signo y los complemento a 2 se suman , y el CV = 0001_0000
- Aplicando la lógica de la eliminación de extensión de signo y sumando el CV a los PPs, la multiplicación se realiza de nuevo dando el mismo resultado, como se puede ver en la figura "b" de la siguiente imagen.
- Como el CV tiene un solo bit distinto de cero, el bit se añade con el primer PP (mostrado en gris).
- Esta técnica ahorra área y por lo tanto es muy eficaz.
![[Pasted image 20240219113409.png]]

### Digito canonico con signo
- Este concepto solo se puede aplicar a las constantes
- Hasta ahora sólo se han representado números en forma de complemento a 2, donde cada bit es 0 o 1.
- También existen otras formas para representar números.
- Algunas pocos son eficaces para el diseño de sistemas de procesamiento de señales, como ser el dígito canónico con signo (CSD).
- En CSD, un dígito puede ser 1, 0 o -1.
- La representación restringe la ocurrencia de 2 dígitos distintos de ceros consecutivos en el número, generando una representación única con un número mínimo de dígitos distintos de cero.
- El CSD de un número se puede calcular utilizando la propiedad de cadena de los números.
- Esta propiedad, mientras pasa de LSB a MSB, encuentra sucesivamente cadenas de 1s y las reemplaza con un valor equivalente, usando 1, 0 o -1.
- Considerando el número 7, este puede escribirse como 8-1, o en CSD como:
	- 0111 = 1000-1 = 1001
- El bit con una barra tiene peso negativo y los demás tienen peso positivo.
- De forma similar, el 31 puede escribirse como 32-1, o en CSD como:
	- 011111 = 100000-1 = 100001
- Así, de forma equivalente, una cadena de 1s se reemplaza con 1 en el 1 menos significativo de la cadena, y un 1 es colocado después del 1 más significativo de la cadena, muestra que todos los demás bits se llenan de ceros.
- Se puede extender de manera trivial esta transformación a cualquier cadena de 1s en representación binaria de un número.
- La propiedad de cadena se puede aplicar recursivamente en representaciones binarias de un número.
- El número transformado tiene un número mínimo de bits distintos de cero.
![[Pasted image 20240219113514.png]]



## Multiplicación por Constantes
### Introduccion
#### En donde se utiliza?
- En muchos sistemas de procesamiento digitales (DSP) y algoritmos de comunicación, una gran proporción de multiplicaciones son números constantes.
- Por ejemplo:
	- Filtros de respuesta de impulso finito (FIR).
	- Filtros respuesta de impulso infinito (IIR).
	- La transformada de coseno discreta (DCT).
	- La transformada de coseno discreto inverso (IDCT).
	- La transformada rápida de Fourier (FFT).
	- La transformada rápida de Fourier inversa (IFFT).
- Para una arquitectura totalmente dedicada (FDA), donde la multiplicación por una constante se asigna a un multiplicador dedicado, no se requiere la complejidad de un multiplicador de propósito general.
- La representación binaria de una constante muestra claramente los bits distintos de cero que requieren la generación de productos parciales (PP), mientras que los bits que son cero en la representación se pueden ignorar para la operación de generación de PP.
- La representación CSD(codificacion canonica) puede reducir aún más el número de productos parciales.




#### Concepto
- Es un código de dígito signado radix-2.
- Codifica una constante usando dígitos signados 1, 0 y -1.
- Representación de constante de N-bits:
![[Pasted image 20240219181935.png]]
- Propiedades
	- No hay dos bits consecutivos en la representación de CSD de un número que no sean cero.
	- La representación de CSD de un número usa un número mínimo de dígitos distintos de cero.
	- La representación de CSD de un número es única.


La representación de CSD de un número se puede calcular recursivamente usando la propiedad de la cadena.
El LSB en una cadena de 1s se cambia a 1 que representa -1, y todos los otros 1s en la cadena se reemplazan por ceros, y el 0 que marca el final de la cadena se cambia a 1.
Después de reemplazar una cadena por su dígitos CSD equivalentes, el número se observa nuevamente moviéndose desde el dígito codificado al MSB para contener cualquier cadena adicional de 1s.
El proceso se repite hasta que no se encuentre una cadena de 1 en el número.


# Otras estrategias
## Operaciones con Barrel Shifter
### Division con desplazador
- Un desplazador lógico de N bits implementa la operación x >> s, donde s es un número entero signado.
- Se implementa a través del conexionado de todos los desplazamientos posibles como entrada de un multiplexor y luego se selecciona la salida apropiada usando el número s.
- Este desplazador puede llegar a implementar divisiones pero estas solo seria con un multiplo de 2
#### Ejemplos de diseño de desplazadores
- En la imagen de la izquierda se puede observar el diseño del desplazador, donde x es el operador de entrada y todos los posibles desplazamientos son realizados previamente e ingresados en el multiplexor en el cual el número s es usado como selector.
- Para un número s negativo el desplazador tomará el valor positivo y realizará el desplazamiento hacia la izquierda.
- El diseño puede ser fácilmente extendido para encargarse de desplazamientos aritméticos y lógicos, esto lo podemos observar en la imagen derecha.
- Para esto primero se debe seleccionar ya sea el bit de signo o 0 para anexar apropiadamente a la izquierda del operador para lograr una operación de desplazamiento a la derecha.
- Para una operación de desplazamiento a la izquierda el diseño para ambas, desplazamiento aritmético y lógico es el mismo.
- Cuando no hay suficientes bits de signo redundantes, el desplazamiento hacia la izquierda provocará overflow.
![[Pasted image 20240219091600.png]]

### Barrel Shifter
- En lugar de usar un multiplexor con múltiples entradas, un barrel shifter puede también ser construido en forma jerárquica.
- Se pueden implementar fácilmente pipelines en este diseño. La técnica puede funcionar tanto para el desplazamiento hacia la derecha como hacia la izquierda.
- Para x >> s, la técnica trabaja considerando s como un número de complemento a dos con signo donde el bit de signo tiene peso negativo y el resto de los bits poseen peso positivo.
- Pasando de los bits más significativos a los menos significativos, cada etapa del barrel shifter solo abastece un bit y realiza el desplazamiento requerido igual al peso de el bit.
- Esto permite realizar divisiones que no solo sean potencia de 2

#### Ejemplo de barrel shifter 16 bits
- En imagen de la siguiente diapositiva se presenta un barrel shifter capaz de desplazar un número x de 16 bits por un número s de 5 bits signado. Con lo cual el desplazador puede realizar corrimientos del 0 al 15 hacia la derecha y del 1 al 16 hacia la izquierda en 5 etapas o niveles.
- Primero el desplazador chequea si es requerido un desplazamiento lógico o aritmético y selecciona apropiadamente 0 o el bit de signo del operando para luego agregarlo para la operación de desplazamiento hacia la derecha.
- Luego el desplazador chequea el bit más significativo de s, ya que este bit posee peso negativo.
- Si $s[4] = 1$, se realiza un desplazamiento a la izquierda de 16 y mantiene el resultado como un número de 31 bits.
- En el caso que $s[4] = 0$, el número es apropiadamente extendido a un número de 31 bits para el siguiente nivel para lograr desplazamientos apropiados.
- Para el resto de los bits la lógica realiza un desplazamiento a la derecha igual al peso de el bit bajo consideración, y el diseño sigue reduciendo el número de bits al ancho requerido a la salida de cada etapa.
![[Pasted image 20240219092018.png]]
##### Aplicandole pipeline
![[Pasted image 20240219092134.png]]

### Multiplicacion con Barrel Shifter
- Un barrel shifter puede también usarse como un multiplicador dedicado en las FPGAs.
- Un desplazamiento por s hacia la izquierda significa una multiplicación por 2s.
- Un desplazamiento a la derecha por s equivale a una multiplicación por 2􀀀s.
- Para realizar esta operación el número por el que se desea multiplicar debe ser potencia de 2.





## Arquitecturas Dedicadas de Filtros FIR
- Podemos colocar solo registros en la entrada y salida de nuestro sistema, porque si lo intentamos hacer en el medio del sistema, se rompe la cadena de acarreo

### Forma directa
El filtro FIR es muy común en aplicaciones de procesamiento de señal.
Un filtro FIR se implementa como
![[Pasted image 20240219182519.png]]
Una implementación del FIR requiere que todas estas multiplicaciones y adiciones se ejecuten simultáneamente, requiriendo L multiplicadores y L-1 sumadores.
La multiplicación con coeficientes constantes puede explotar la simplicidad del multiplicador CSD.
Cada uno de estos multiplicadores, en muchas instancias de diseño, se simplifica aún más al restringir a cuatro el número de dígitos CSD distintos de cero en cada coeficiente.
Un dígito de CSD distinto de cero en un coeficiente contribuye aproximadamente 20 dB de atenuación de banda de corte.
La atenuación de la banda de corte es una medida de la efectividad de un filtro.
![[Pasted image 20240219182622.png|400]]

### Forma directa transpuesta
La estructura de filtro FIR de forma directa da como resultado una gran nube combinacional de árbol de reducción y CPA.
El camino crítica consiste en un multiplicador y un sumador.
Agregar pipeling para reducir el camino crítico causa latencia y una gran sobrecarga de área en la implementación de registros.
Retiming es una técnica efectiva para mover sistemáticamente retrasos algorítmicos en un diseño para reducir el camino crítica del circuito lógico.
La técnica retiming se aplica para transformar el filtro FIR directo en transpuesto.
Es interesante observar que de esta forma, sin agregar registros de pipeling, los retrasos del algoritmo se mueven sistemáticamente usando la transformación de retiming desde el borde superior del DFG al borde inferior.
![[Pasted image 20240219183519.png|400]]
![[Pasted image 20240219183521.png|400]]
![[Pasted image 20240219183522.png|400]]




##  Aritmética Distribuida
- La aritmética distribuida (DA) es otra forma de implementar un producto punto donde una de las matrices tiene elementos constantes.
- El DA se puede utilizar de manera efectiva para implementar algoritmos de tipo FIR, IIR y FFT.
- La lógica DA reemplaza la operación MAC de la suma de convolución en una lectura de tabla de búsqueda en serie de bits y operación de adición.
- Teniendo en cuenta la arquitectura de los FPGA, los diseños efectivos de tiempo/área pueden implementarse usando técnicas DA.
- La lógica de DA funciona expandiendo primero la matriz de números variables en el producto punto como un número binario y luego reorganizando los términos de MAC con respecto al peso de los bits.
![[Pasted image 20240219183720.png|100]]
- Donde K, Ak y xk es la longitud de ambas matrices, los elementos de una matríz de constantes y variables, respectivamente.


![[Pasted image 20240219183831.png|400]]
![[Pasted image 20240219183835.png|400]]
![[Pasted image 20240219183838.png|400]]
![[Pasted image 20240219183840.png|400]]
![[Pasted image 20240219183841.png|400]]
![[Pasted image 20240219183842.png|400]]









# Unisa



## Multiplicador
- El retardo de un multiplicador basico es de $3N-2$
	- Para un numero muy alto de bit se puede redondear en 3N

### Estructura matricial optimizada
![[Pasted image 20231106095948.png|600]]
- El retardo es de N+VMA

### Multiplicacion y suma
- Tambien llamada MACC(multiplicacion y acumulador)
- Estariamos realizando la operacion de $$Y=AxB+C$$
- Donde A y B son de 3 bits y C de 6 bits
- Para poder realizar esta operacion al bloque de multiplicacino optimizado, a cada primer bloque de cada columna le colocamos de entrada de carry el valor correpondiente de C
![[Pasted image 20231106102702.png|500]]
- Con este bloque tambine podemos realizar la convolucion solo agregando un registro a la salida del bloque y que esta sea la entrada de suma y que las entradas de multiplicacion sea la correpondiente 
- Con este mismo bloque podemos implementar el bloque para realizar la suma de numero en complemento a 2


### Multiplicador WALLACE
Para ver esta modificacion analisamos un multiplicador de 4 bits
![[Pasted image 20231106110610.png|600]]
- Cambiamos la estrutucra de la izquierda por la de la derecha para ahorrar un sumador y 2 tiempos de retardo
- Basicamente se usa un compresor 10→4
- Esta estructura se llama **WALLACE**






## Observaciones
### Codificacion en signo e numero
- Los numeros binarios suelen contar con cierto tipos de codificaciones para poder expresar valores negativos
![[Sistemas de numeracion#Representacion de numeros signados]]
- Es importante usar el complemento a 2 porque de esta manera, podemos hacer una resta con el mismo sistema de la suma
- Si usaramos complemento a 1 deberiamos hacer 2 operaciones para esto
- Si usaramos solo modulo y signo no poderiamos usar el mismo sistema
- Ademas con complemento a 2 evitamos 2 representraiones para el 0

### Evitar diseño compuertas
Pensando en los [Niveles de abstaccion]([[Los 4 niveles de abstraccion]]), el diseñador debe evitar el nivel de compuertas y solo concentrarse en el modelado a nivel RTL
- Pero para esto debe conocer las librerias de la tecnologia que esta usando
- Aunque, independientemente de la tecnologia, debe diseñar en nivel RTL

















# Referencias
### Notas relacionadas
- **Nota:**[[1. Memories semiconductoras]]
	- **Relacion-Reflexion:** Aqui se hace uso de la memoria para logico, lo cual es muy importante
- **Nota:** [[Procesamiento Digital de Seniales]]
	- **Relacion-Reflexion:** Vemos como se puede hacer mas eficiente circuitos de este tipo
- **Nota:** [[2. FPGA]]
	- **Relacion-Reflexion:** Se analiza que sumador sirve para FPGA y cual para ASIIC