
## Capas Fundamentales de ConvNets
![[Captura de pantalla 2024-10-03 a las 10.33.18 a. m..png]]

![[Captura de pantalla 2024-10-03 a las 10.37.24 a. m..png]]




### Capa Convolucional
La **capa convolucional** es el núcleo de las ConvNets y se encarga de realizar la operación conocida como "convolución" sobre la entrada. Esta operación consiste en aplicar un conjunto de **filtros** o **kernels** a la entrada (por ejemplo, una imagen) para extraer características específicas. Los filtros se mueven sobre la entrada utilizando un valor conocido como **stride**, y opcionalmente se aplica **padding** para controlar el tamaño de la salida.
![[Captura de pantalla 2024-10-03 a las 10.34.35 a. m..png]]
La salida de una capa convolucional es conocida como un **mapa de características** (feature map), que contiene información sobre qué características detectó cada filtro en cada posición.
#### Kernels
Son pequeños "bloques" de tamaño fijo (como 3x3 o 5x5) que actúan como detectores de características. Cada filtro responde a un patrón específico, como bordes o texturas.
![[Captura de pantalla 2024-10-03 a las 10.30.14 a. m..png]]
![[Captura de pantalla 2024-10-03 a las 10.30.30 a. m..png]]


Se puede aplicar la siguiente formula para calcular las dimensiones de la red luego de aplicar la convolucion.
![[Captura de pantalla 2024-10-03 a las 10.41.31 a. m..png|300]]
#### Stride
Es la cantidad de pasos que un filtro se desplaza cada vez que aplica la convolución. Un stride de valor 1 se mueve un píxel a la vez, mientras que valores mayores reducen la superposición entre aplicaciones.
![[Captura de pantalla 2024-10-03 a las 10.22.29 a. m..png|300]]

![[Captura de pantalla 2024-10-03 a las 10.22.12 a. m..png|300]]

#### Padding
Es una técnica que agrega valores alrededor de la entrada (generalmente ceros) para conservar las dimensiones de la salida o para ajustar la misma con los bordes. Los dos tipos principales son:
  - **Padding "same"**: La salida tiene el mismo tamaño que la entrada.
  - **Padding "valid"**: Sin agregar valores, la salida se reduce con cada operación.
![[Captura de pantalla 2024-10-03 a las 10.21.38 a. m..png]]




### Capa de Pooling
La **capa de pooling** tiene como objetivo reducir la dimensionalidad de los mapas de características, preservando la información más relevante. De este modo, la red se vuelve más eficiente y menos susceptible a pequeñas variaciones en la entrada.
![[Captura de pantalla 2024-10-03 a las 10.23.11 a. m..png]]
- **Max-pooling**: Selecciona el valor máximo dentro de una región específica (ej., 2x2). Este método se utiliza comúnmente porque retiene los elementos más destacados de una región.
- **Average-pooling**: Calcula el promedio de todos los valores dentro de una región específica. Se utiliza en casos donde la información promedio de una región es más relevante que los extremos.
![[Captura de pantalla 2024-10-03 a las 10.35.05 a. m..png]]
El **pooling** ayuda a las ConvNets a ser invariables a pequeñas traslaciones y ruidos en la entrada, y también contribuye a la reducción del número de parámetros, mejorando la eficiencia.
El **Max-Pooling** retiene solo las características más prominentes de una región, permitiendo que las características más importantes sobrevivan a cada reducción.

#### Conv+ Pool
Aqui podemos ver como nuestra imagen(matriz de 2 dimensiones de entrada), al aplicarle diversor filtros va ganando profundida como tensor pero va perdiendo tamaño por el pool
![[Captura de pantalla 2024-10-03 a las 10.35.27 a. m..png]]
#### Flatten
Esta capa es la encargada de llevar nuestra matriz de 2 dimensiones de las caracteristicas de la imagen a un vector para luego poder ser procesado en la capa totalmente conectada
![[Captura de pantalla 2024-10-03 a las 10.35.54 a. m..png]]
### Capas Totalmente Conectadas (Fully Connected Layers)
Las **capas totalmente conectadas** son similares a las de una red neuronal tradicional y se colocan en la parte final de una ConvNet. Estas capas toman las características extraídas por las capas convolucionales y de pooling, y las utilizan para realizar la clasificación o regresión.

- **Conexiones Complejas**: Cada neurona está conectada a todas las neuronas de la capa anterior. Esto permite que la red pueda combinar todas las características para llegar a una decisión.
- **Actúan como Clasificadores**: En una red típica, las capas totalmente conectadas son responsables de la decisión final. Las características extraídas se combinan para formar probabilidades de clases.

### Capas opcionales
#### Capas Relu
En esta capa aplicación la función de activación Relu luego de una convolucion
![[Captura de pantalla 2024-10-03 a las 11.25.38 a. m..png]]

#### Capaz de normalizacion
![[Captura de pantalla 2024-10-03 a las 12.10.29 p. m..png]]
Como nuestros valores se van modificando, estos se van desnormalizadno por lo cual muchaveces es bueno colocar capas intermedias de batch normalizacion

### Otros conceptos importantes
#### 1. CNN Feature Extractors: Receptive Field (RF) y Effective Receptive Field (ERF)

- **Receptive Field (RF)**:
    
    - El **campo receptivo** (RF) es la región de la entrada que influye en la activación de una neurona en una capa posterior.
    - A medida que se avanza en una ConvNet, el RF de las neuronas se expande, permitiendo que cada neurona "vea" una porción más grande de la imagen. Esto permite detectar características de mayor escala.
- **Effective Receptive Field (ERF)**:
    
    - El **ERF** se refiere a la región de entrada que tiene una contribución significativa a la salida de una neurona.
    - Aunque el RF define una región total de influencia, en la práctica, solo ciertas áreas contribuyen significativamente debido a la **distribución gaussiana** de la influencia. El ERF tiende a ser menor que el RF total.

## C. Convoluciones Avanzadas
Algunas variantes de las capas convolucionales se han desarrollado para extender la funcionalidad básica:

- **Convoluciones Dilatadas (Dilated Convolutions)**: Utilizan un espacio entre los valores de los filtros para aumentar el "campo receptivo" sin aumentar el número de parámetros. Son útiles en tareas como la segmentación de imágenes, donde se necesita una visión más amplia del contexto.
- **Convoluciones Transpuestas (Transposed Convolutions)**: También conocidas como **deconvoluciones**, se utilizan para realizar operaciones de upsampling, aumentando la resolución espacial de los mapas de características. Son fundamentales en tareas como la generación de imágenes y la segmentación en redes como U-Net.

