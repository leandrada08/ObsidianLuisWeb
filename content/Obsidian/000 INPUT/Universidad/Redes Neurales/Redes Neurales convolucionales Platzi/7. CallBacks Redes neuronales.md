
##  Optimizaciones de Modelos y Callbacks

### Callbacks para Optimización del Entrenamiento
Los **callbacks** son herramientas que permiten interactuar con el proceso de entrenamiento, mejorando el rendimiento y optimizando el uso de recursos. En las ConvNets, se emplean para modificar el comportamiento del entrenamiento en respuesta a ciertas condiciones, lo cual es crucial para garantizar una buena convergencia y evitar problemas como el sobreajuste o la degradación del rendimiento.

#### EarlyStopping
- **Descripción**: **EarlyStopping** es una técnica que permite detener el entrenamiento de la red cuando la métrica de validación deja de mejorar durante un número determinado de épocas consecutivas.
- **Ventaja**: Evita el **sobreentrenamiento**, reduciendo el riesgo de que el modelo se adapte demasiado a los datos de entrenamiento y pierda capacidad de generalización.
- **Funcionamiento**: EarlyStopping monitoriza una métrica específica, como la **pérdida de validación** o la **precisión**, y si no mejora durante "n" épocas consecutivas, el entrenamiento se detiene.

#### ModelCheckpoint
- **Descripción**: El callback **ModelCheckpoint** guarda el modelo durante el proceso de entrenamiento, dependiendo de una métrica de evaluación.
- **Ventaja**: Permite conservar el mejor modelo encontrado durante el entrenamiento, lo cual es útil cuando el modelo empieza a sobreentrenarse y la métrica de validación comienza a degradarse.
- **Funcionamiento**: Se guarda una copia del modelo cada vez que la métrica de validación alcanza un valor óptimo (por ejemplo, la menor pérdida o la mayor precisión).

#### Learning Rate Scheduler Callback
El **learning rate** (tasa de aprendizaje) tiene un impacto significativo en la eficiencia del proceso de optimización. Los **schedulers** permiten ajustar el learning rate dinámicamente durante el entrenamiento.

- **Reducción del Learning Rate en una Métrica Específica**:
  - **ReduceLROnPlateau**: Este callback reduce la tasa de aprendizaje cuando la métrica de validación se estabiliza (o se encuentra en una "meseta"), permitiendo que el optimizador se mueva con pasos más pequeños y busque mínimos locales con mayor precisión.
  - **Ventaja**: Esto es especialmente útil cuando el modelo parece estar alcanzando un punto de saturación y necesita un ajuste más fino para lograr mejorar.

- **Schedule basado en Épocas**:
  - Se puede utilizar un **esquema de reducción exponencial** o un **ciclo triangular** para incrementar y decrementar el learning rate periódicamente.
  - **Warm-Up**: Aumenta gradualmente el learning rate durante las primeras épocas para estabilizar el entrenamiento inicial y evitar grandes saltos en los pesos.





# Callback: early stop y ckeckpoints en keras
### 1. **Early Stopping**
El **Early Stopping** es un callback que se utiliza para prevenir el **sobreajuste** (`overfitting`). Este callback supervisa la métrica del rendimiento del modelo (por ejemplo, la pérdida o la precisión en el conjunto de validación) y detiene el entrenamiento cuando dicha métrica deja de mejorar durante un número consecutivo de épocas.

**¿Cómo funciona?**

- Durante el entrenamiento, **Early Stopping** supervisa una métrica determinada, como la `val_loss` (pérdida en los datos de validación).
- Si la métrica no mejora después de un número específico de épocas consecutivas (definido por el parámetro `patience`), el entrenamiento se detiene.
- Esto permite evitar que el modelo continúe entrenando y sobreajustándose a los datos de entrenamiento, logrando así un mejor generalización.

**Implementación en Keras**:

```python
from tensorflow.keras.callbacks import EarlyStopping

early_stopping = EarlyStopping(
    monitor='val_loss',  # Métrica a monitorear, en este caso la pérdida de validación.
    patience=3,          # Número de épocas sin mejora antes de detener el entrenamiento.
    restore_best_weights=True  # Restaurar los mejores pesos obtenidos durante el entrenamiento.
)

# Al entrenar el modelo:
model.fit(
    x_train, y_train,
    validation_data=(x_val, y_val),
    epochs=50,
    callbacks=[early_stopping]
)
```

**Parámetros importantes**:

- **`monitor`**: Define la métrica que se supervisará (`val_loss`, `val_accuracy`, etc.).
- **`patience`**: Número de épocas que se esperarán sin mejora antes de detener el entrenamiento. Un valor alto permite tolerar fluctuaciones.
- **`restore_best_weights`**: Permite restaurar automáticamente los mejores pesos, evitando que el modelo tenga los parámetros de la última época (la cual puede no ser la mejor).

### 2. **Model Checkpoints**
El **Model Checkpoint** es un callback que permite guardar los **pesos del modelo** durante el entrenamiento, normalmente cuando se obtiene el mejor rendimiento hasta el momento. Es una excelente manera de asegurarse de no perder el mejor modelo si algo sale mal durante el entrenamiento o para utilizar los mejores pesos una vez finalizado.

**¿Cómo funciona?**

- **Model Checkpoint** guarda los pesos del modelo en un archivo cada vez que mejora la métrica supervisada.
- Se puede configurar para guardar solo los mejores pesos (cuando el modelo tiene la mejor métrica) o para guardar el modelo periódicamente.

**Implementación en Keras**:

```python
from tensorflow.keras.callbacks import ModelCheckpoint

checkpoint = ModelCheckpoint(
    filepath='mejor_modelo.h5',  # Ruta donde se guardarán los pesos.
    monitor='val_accuracy',      # Métrica a monitorear, en este caso la precisión de validación.
    save_best_only=True,         # Guardar solo si el modelo mejora la métrica monitoreada.
    mode='max',                  # Indica que queremos maximizar la métrica (p. ej., precisión).
    verbose=1                    # Muestra un mensaje cada vez que se guarda un modelo.
)

# Al entrenar el modelo:
model.fit(
    x_train, y_train,
    validation_data=(x_val, y_val),
    epochs=50,
    callbacks=[checkpoint]
)
```

**Parámetros importantes**:

- **`filepath`**: Ubicación donde se guardará el modelo o los pesos. Normalmente se guarda en un archivo `.h5`.
- **`monitor`**: Métrica que se supervisará para decidir cuándo guardar el modelo (`val_loss`, `val_accuracy`, etc.).
- **`save_best_only`**: Si es `True`, guarda solo los mejores pesos en lugar de guardar cada época.
- **`mode`**: Puede ser `'max'`, `'min'`, o `'auto'`, indicando si queremos maximizar (p. ej., `accuracy`) o minimizar (p. ej., `loss`) la métrica monitoreada.

### Ejemplo de Uso Combinado
En la práctica, es muy común usar ambos callbacks a la vez para mejorar el rendimiento del entrenamiento y asegurarse de que se guarde siempre la mejor versión del modelo:

```python
model.fit(
    x_train, y_train,
    validation_data=(x_val, y_val),
    epochs=50,
    callbacks=[early_stopping, checkpoint]  # Utilizando Early Stopping y Model Checkpoints.
)
```
- **`EarlyStopping`** garantiza que el entrenamiento se detenga antes de sobreajustar.
- **`ModelCheckpoint`** se asegura de que los mejores pesos del modelo se guarden, incluso si se interrumpe el entrenamiento.


