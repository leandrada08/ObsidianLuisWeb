
## Visualización de Activaciones y Características Aprendidas
La visualización de lo que aprende una ConvNet es fundamental para comprender cómo está transformando los datos de entrada en representaciones útiles para la clasificación o detección de características.

### Activaciones de Capas
- **Activación de Capas Intermedias**: Consiste en inspeccionar las salidas de cada una de las capas convolucionales para ver qué patrones está capturando cada filtro.
  - Por ejemplo, las capas iniciales tienden a detectar **bordes y patrones simples**, mientras que las capas más profundas capturan **características más abstractas**, como formas complejas o partes de objetos.
- **Mapas de Características (Feature Maps)**: Los mapas de características se pueden visualizar para evaluar qué áreas de la imagen de entrada tienen una mayor contribución a la predicción de la red.
![[Captura de pantalla 2024-10-03 a las 11.30.27 a. m..png]]

### Análisis por Pesos

- **Visualización de los Filtros**: Es posible visualizar los pesos aprendidos por cada filtro convolucional para entender qué patrones están capturando. Al inicio del entrenamiento, los pesos se inicializan con valores aleatorios, pero con el tiempo los filtros desarrollan estructuras que representan características visuales importantes.
- **Inspección Directa de los Pesos**: Especialmente en las primeras capas, los pesos pueden visualizarse como patrones que buscan bordes, líneas o texturas. Un análisis de estos pesos puede dar una idea de cómo de robusto o eficiente es el modelo en detectar patrones.
![[Captura de pantalla 2024-10-03 a las 11.32.18 a. m..png]]
### Análisis por Imágenes que Activan Mayormente un Filtro

- **Imagen que Maximiza la Activación**: Se puede generar una imagen sintética que maximice la activación de un filtro específico. Esto se logra ajustando una imagen inicial hasta que se active lo más posible el filtro que queremos visualizar. Esto permite entender qué características específicas hace que el filtro reaccione.
- **Visualización de Patrones Clave**: Esta técnica permite ver cuáles son las entradas que mejor representan lo que un filtro particular está aprendiendo. Generalmente, los filtros de las capas profundas responden a partes de objetos específicos.
![[Captura de pantalla 2024-10-03 a las 11.32.34 a. m..png]]
### Recuperación de Imágenes Usando Características Intermedias
- **Recuperación de Imágenes Similares**: Utilizando las activaciones de las capas intermedias de una ConvNet, se pueden comparar imágenes entre sí.
  - En aplicaciones de búsqueda por contenido, se extraen las características de una imagen mediante la red, y se busca en un conjunto de datos aquellas imágenes que tienen una representación similar.
![[Captura de pantalla 2024-10-03 a las 11.34.06 a. m..png]]
### Codificación t-SNE para Visualización de Características
- **t-SNE (t-distributed Stochastic Neighbor Embedding)**: Es una técnica de reducción de dimensionalidad que permite visualizar en dos o tres dimensiones las relaciones entre características de alto nivel aprendidas por la ConvNet.
  - **Aplicación**: Es útil para observar cómo las representaciones internas separan las diferentes clases en el espacio latente, proporcionando una visión cualitativa de la calidad del aprendizaje de la red.
![[Captura de pantalla 2024-10-03 a las 11.33.47 a. m..png]]


## Técnicas de Interpretación
Las técnicas de interpretación nos ayudan a comprender por qué la ConvNet toma ciertas decisiones. Esto es especialmente importante en aplicaciones sensibles, como las médicas, donde se requiere entender y confiar en el comportamiento del modelo.

### Ocultar Partes de la Imagen
- **Occlusion Sensitivity**: Se ocultan diferentes regiones de la imagen (usualmente aplicando un bloque negro sobre diferentes partes) y se evalúa el impacto en la salida.
  - **Objetivo**: Determinar qué partes de la imagen son más importantes para la predicción del modelo.
  - **Aplicación**: Puede ayudar a entender cómo la red localiza características relevantes, y si está basando su decisión en patrones correctos.

### Gradiente de Datos (Saliency Maps)
- **Saliency Maps**: Esta técnica utiliza el gradiente de la salida con respecto a la entrada para determinar qué píxeles influyen más en la predicción.
  - **Cálculo**: Se calcula la derivada de la probabilidad de la clase objetivo con respecto a los píxeles de la imagen de entrada. Esto produce un "mapa de saliencia" que muestra las regiones más influyentes.
  - **Utilidad**: Permite identificar qué parte de la imagen tiene el mayor impacto en la decisión del modelo. Es útil para verificar que el modelo se esté centrando en características razonables.

### DeconvNet
- **Deconvoluciones**: DeconvNet es una técnica que reconstruye la imagen original desde un mapa de características. Invirtiendo las operaciones realizadas por la ConvNet, se puede ver qué activaciones de las capas convolucionales corresponden a patrones en la imagen original.
  - **Visualización Inversa**: Permite reconstruir la representación interna y asociarla con una entrada visual, proporcionando una comprensión más clara de qué patrones específicos detectan los filtros de la red.

### Grad-CAM (Gradient-weighted Class Activation Mapping)
- **Grad-CAM**: Utiliza gradientes de la última capa convolucional para generar un mapa de calor que muestra las áreas de la imagen que influyeron más en la predicción.
  - **Funcionamiento**: Los gradientes se ponderan con las activaciones y se aplican sobre la imagen de entrada. Esto da una visualización de qué áreas están "siendo vistas" por la red para una clase específica.
  - **Aplicación Práctica**: Se usa a menudo en la interpretación de decisiones en modelos complejos, proporcionando una explicación visual fácilmente comprensible.

## Análisis de Limitaciones y Desafíos de ConvNets
Las técnicas de visualización e interpretación también permiten evaluar las **limitaciones** y posibles vulnerabilidades de las ConvNets.

### Ejemplos Adversariales
- **Definición**: Los **ejemplos adversariales** son entradas ligeramente modificadas (casi imperceptibles para el ojo humano) que resultan en predicciones incorrectas por parte de la red.
- **Importancia en la Interpretación**: Las técnicas de interpretación permiten entender qué características específicas hacen que una ConvNet sea vulnerable a estos ejemplos. El análisis de ejemplos adversariales revela que la red puede estar sobreajustada a patrones específicos en lugar de aprender características robustas.

### Comparación con el Rendimiento Humano
- **Desempeño Comparativo**: A pesar de que las ConvNets pueden superar el rendimiento humano en algunas tareas de clasificación, su falta de comprensión contextual y su vulnerabilidad a perturbaciones sutiles muestran diferencias importantes con el procesamiento visual humano.
- **Técnicas de Interpretación y Desempeño**: El uso de técnicas de interpretación permite observar las diferencias entre los patrones a los que las ConvNets son sensibles y aquellos que los humanos consideran relevantes.

