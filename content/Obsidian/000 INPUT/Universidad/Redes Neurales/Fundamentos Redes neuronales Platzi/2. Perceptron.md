
### Introduccion
La neurona, también llamado perceptrón (nacido en los años 50's) está inspirado en las redes neuronales biológicas.
Un perceptrón tiene tres componentes principales:
1. **Entradas** ($x_1, x_2, \ldots, x_n$): Los valores que representan las características del dato.
2. **Pesos** ($w_1, w_2, \ldots, w_n$): Cada entrada tiene un peso asociado que determina su influencia en la salida. Estos pesos se ajustan durante el proceso de entrenamiento.
3. **Función de Activación**: Determina si la neurona se activa o no (esto es, si produce una salida positiva o negativa). En el perceptrón básico, se suele usar la **función escalón**.
![[Captura de pantalla 2024-10-01 a las 10.38.51 a. m..png|600]]
### Modelo Matemático del Perceptrón
El perceptrón puede ser descrito de manera matemática  en 2 partes, tiene su combinacion lineal y su funcion de activacion.

$$
y = f(z)
$$

- **$z$** es la **combinación lineal** de las entradas ponderadas más el sesgo.
- **$f(z)$** es la salida después de aplicar la función de activación. 

#### Combinación lineal
$$
z = \sum_{i=1}^n w_i x_i + b
$$
Donde:
- $x_i$: Entrada $i$ de la neurona.
- $w_i$: Peso asociado a la entrada $x_i$.
- $b$: Término de sesgo (**bias**), que permite desplazar la función de activación y ayuda a mejorar la flexibilidad del modelo.

Reescribiendola con la funcion de activacion nos quedaria: $$
y = f\left(\sum_{i=1}^n w_i x_i + b\right)
$$

#### Funcion de activacion
- $f$: Función de activación. En el perceptrón clásico, $f$ es una función escalón que devuelve 1 si la entrada es mayor o igual a 0, y 0 en caso contrario:

$$
f(z) = \begin{cases} 
1 & \text{si } z \geq 0 \\
0 & \text{si } z < 0 
\end{cases}
$$
Hay otros tipos de [[Funciones de activacion]]


#### Bias
Nos permite dar elasticidad del modelo
![[Captura de pantalla 2024-10-01 a las 10.44.11 a. m..png]]



### Entrenamiento del Perceptrón
El perceptrón aprende ajustando sus pesos mediante un algoritmo simple, llamado el **algoritmo de aprendizaje del perceptrón**, basado en la idea de reducir el error de clasificación. El proceso funciona de la siguiente manera:

1. **Inicialización**: Se inicializan los pesos de manera aleatoria, típicamente pequeños valores cercanos a cero.
2. **Actualización de Pesos**: Los pesos se ajustan cada vez que el perceptrón comete un error de clasificación. La regla de actualización es:

$$
w_i \leftarrow w_i + \eta \cdot (y_{\text{real}} - y_{\text{predicho}}) \cdot x_i
$$

- **$\eta$**: Tasa de aprendizaje, un parámetro que controla qué tan grandes son los ajustes de los pesos.
- **$y_{\text{real}}$** y **$y_{\text{predicho}}$**: Valor real de la clase y la predicción del perceptrón, respectivamente.

3. **Sesgo**: El sesgo también se ajusta según:

$$
b \leftarrow b + \eta \cdot (y_{\text{real}} - y_{\text{predicho}})
$$

El proceso se repite hasta que el perceptrón clasifica correctamente todas las muestras o hasta que se alcance un número máximo de iteraciones.

###  Limitaciones del Perceptrón
El perceptrón clásico tiene una limitación importante: solo puede resolver problemas que son **linealmente separables**. Esto significa que puede clasificar correctamente conjuntos de datos que se puedan dividir mediante una línea (en 2D), un plano (en 3D), o un hiperplano en espacios de dimensión superior.

Un ejemplo clásico del problema que no puede resolver el perceptrón básico es el problema **XOR**. En XOR, no hay un hiperplano que pueda dividir correctamente las dos clases, ya que no son linealmente separables.

![[Captura de pantalla 2024-10-01 a las 10.58.15 a. m..png|400]]
![[Captura de pantalla 2024-10-01 a las 10.59.45 a. m..png|300]]
Para resolver este problema es necesario agregar un perceptron mas
![[Captura de pantalla 2024-10-01 a las 11.00.26 a. m..png|400]]
Esto es el punta pie de las [[Arquitectura de una red neuronal]]
### Ejemplo Numérico del Perceptrón
Supongamos un perceptrón con dos entradas ($x_1$ y $x_2$), y queremos entrenarlo para resolver un problema simple de clasificación binaria:

- **Datos de entrenamiento**: $(x_1, x_2) = (1, 1), (1, 0), (0, 1), (0, 0)$.
- **Etiquetas**: $y_{\text{real}} = 1, 0, 0, 0$ (AND lógico).

Inicialmente, los pesos son aleatorios ($w_1 = 0.5, w_2 = -0.4, b = 0.1$) y la tasa de aprendizaje es $\eta = 0.01$. Luego, usando la regla de actualización, ajustamos los pesos cada vez que el perceptrón se equivoca.

Por ejemplo, si la entrada es $(x_1, x_2) = (1, 0)$:
1. Calculamos $z = 1 \cdot 0.5 + 0 \cdot (-0.4) + 0.1 = 0.6$.
2. La salida predicha $y_{\text{predicho}}$ sería 1.
3. El valor real es 0, entonces cometemos un error. Actualizamos los pesos según:

$$
w_1 = 0.5 + 0.01 \cdot (0 - 1) \cdot 1 = 0.49
$$

De manera similar, se ajustan los otros pesos y el sesgo.
