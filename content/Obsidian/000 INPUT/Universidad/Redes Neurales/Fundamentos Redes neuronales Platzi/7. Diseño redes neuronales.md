

## Introducción al Diseño de Arquitecturas
![[Captura de pantalla 2024-10-02 a las 10.09.04 a. m..png]]
El diseño de una red neuronal implica tomar decisiones sobre cuántas capas usar, cuántas neuronas incluir en cada capa, y cómo estructurar las conexiones entre estas capas. Estas decisiones afectan significativamente la capacidad del modelo para aprender y generalizar a partir de los datos. El objetivo principal del diseño es encontrar una estructura que balancee la **capacidad de representación** con la **capacidad de generalización**.

## Selección del Número de Capas y Neuronas por Capa

### Capas Ocultas

- **Redes Poco Profundas vs. Redes Profundas**:
  - **Redes Poco Profundas**: Tienen una o dos capas ocultas. Pueden ser suficientes para problemas simples, pero tienen limitaciones al representar funciones complejas.
  - **Redes Profundas**: Con múltiples capas ocultas, tienen la capacidad de aprender patrones complejos a través de representaciones jerárquicas. Cada capa aprende características más abstractas que la anterior.

### Neuronas por Capa

- No hay un número exacto que funcione para todas las redes; depende del problema específico y de los datos.
- **Capas más Grandes**: Pueden capturar más información, pero incrementan el riesgo de **overfitting** si hay demasiadas neuronas para una cantidad limitada de datos.
- Un buen enfoque inicial es comenzar con un número moderado de neuronas y luego ajustar en función de los resultados experimentales.

## Teorema de Aproximación Universal

El **teorema de aproximación universal** establece que una red neuronal feedforward con al menos una capa oculta, y un número suficiente de neuronas en dicha capa, puede aproximar cualquier función continua con la precisión deseada. Esto significa que incluso una red con una única capa oculta puede representar funciones complejas, siempre y cuando tenga suficiente capacidad.

Sin embargo, para problemas reales, **la profundidad** suele ser preferible a **la amplitud**, ya que las redes profundas pueden aprender de manera más eficiente representaciones jerárquicas, que son más útiles para la mayoría de los problemas complejos.

## Consideraciones de Diseño

- **Sesgo vs. Varianza (Bias-Variance Tradeoff)**:
  - **Modelos Simples** (alto sesgo) tienden a **subajustar** los datos, es decir, no capturan toda la complejidad de la relación.
  - **Modelos Complejos** (alta varianza) tienden a **sobreajustar**, es decir, se ajustan demasiado a los datos de entrenamiento y no generalizan bien.

- **Capas Especializadas**:
  - **Redes Convolucionales**: Adecuadas para datos con estructura espacial (e.g., imágenes).
  - **Redes Recurrentes**: Adecuadas para datos secuenciales (e.g., series temporales, texto).

---


## MLP para Regresión

Los **Perceptrones Multicapa (MLP)** no solo se utilizan para problemas de clasificación; también son muy eficaces en problemas de regresión, donde el objetivo es predecir un valor continuo.

1. **Arquitectura del MLP para Regresión**
   - Un **MLP para regresión** consiste en múltiples capas densas conectadas entre sí (también conocidas como **fully connected layers**).
   - A diferencia de los problemas de clasificación, la **capa de salida** de un MLP para regresión tiene generalmente una sola neurona que produce un valor numérico.
   - No se utiliza una función de activación en la capa de salida (o, en algunos casos, se utiliza una función `linear`), ya que se desea predecir valores continuos sin restricciones en el rango.

3. **Función de Pérdida y Métrica de Evaluación**
   - En el caso de regresión, una de las funciones de pérdida más utilizadas es el **Error Cuadrático Medio (MSE)**, ya que penaliza de manera más fuerte los errores grandes, ayudando a mejorar la precisión del modelo:

   - Para la métrica de evaluación, se puede utilizar también el **Error Absoluto Medio (MAE)**, que proporciona una evaluación más interpretativa para casos donde se desea entender la magnitud promedio del error de predicción.

![[Captura de pantalla 2024-10-07 a las 10.11.45 a. m..png]]

## MLP para Clasificación
![[Captura de pantalla 2024-10-04 a las 12.33.10 p. m..png]]
![[Captura de pantalla 2024-10-04 a las 12.33.20 p. m..png]]

Los **Perceptrones Multicapa (MLP)** también son muy comunes en problemas de clasificación, donde el objetivo es predecir una clase a partir de un conjunto de características de entrada. En problemas de clasificación, se puede utilizar tanto para clasificación binaria como para clasificación con múltiples clases.

1. **Arquitectura del MLP para Clasificación**
   - Un **MLP para clasificación** también tiene una arquitectura con varias capas ocultas densas. Cada capa oculta utiliza funciones de activación no lineales para mejorar la capacidad del modelo de aprender patrones complejos.
   - La **capa de salida** depende del tipo de problema de clasificación:
     - **Clasificación Binaria**: Para un problema binario, la capa de salida suele tener una sola neurona con la **función de activación sigmoide** (`sigmoid`). Esto permite generar una probabilidad entre 0 y 1, que se puede usar para decidir entre las dos clases.
     - **Clasificación Multiclase**: Para problemas con múltiples clases, la capa de salida tiene tantas neuronas como clases hay, y se utiliza la **función de activación softmax** para obtener probabilidades para cada clase.

3. **Función de Pérdida y Métrica de Evaluación**
   - **Clasificación Binaria**: La función de pérdida que se utiliza normalmente es la **entropía cruzada binaria** (`binary_crossentropy`), ya que está diseñada para problemas donde se desea maximizar la probabilidad de una de dos clases.
   - **Clasificación Multiclase**: Para problemas multiclase, se usa la **entropía cruzada categórica** (`categorical_crossentropy` o `sparse_categorical_crossentropy`), dependiendo de si las etiquetas se presentan en formato categórico o entero.


Los MLP para clasificación son ideales para tareas que incluyen clasificación de imágenes, análisis de texto, entre otros, y la elección de la función de activación en la capa de salida depende de la naturaleza del problema (binario o multiclase). La función **sigmoide** es excelente para predecir probabilidades en problemas binarios, mientras que la **softmax** permite evaluar todas las clases posibles en problemas con más de dos categorías.


## Ajuste de Hiperparámetros en Redes Neuronales

El ajuste de hiperparámetros es un paso crucial en la construcción de redes neuronales efectivas. A diferencia de los parámetros que aprende la red durante el entrenamiento, los **hiperparámetros** se deben ajustar antes de entrenar el modelo. Estos incluyen aspectos como la arquitectura de la red, la tasa de aprendizaje, el tamaño del lote, el número de capas y neuronas, entre otros. 
#### ¿Qué Son los Hiperparámetros en Redes Neuronales?

Los **hiperparámetros** son configuraciones que determinan la estructura del modelo y cómo se entrena. Algunos de los hiperparámetros más comunes en redes neuronales incluyen:

- **Número de Capas Ocultas**: Define la profundidad de la red. Redes más profundas tienen mayor capacidad para aprender características complejas, pero también tienen un mayor riesgo de sobreajuste.
- **Número de Neuronas por Capa**: Define la complejidad de cada capa oculta. Generalmente, se comienza con un valor cercano al tamaño de la entrada y se ajusta dependiendo de la necesidad del problema.
- **Función de Activación**: Las funciones como **ReLU**, **sigmoide**, y **tanh** son usadas para introducir no linealidad en la red. La elección de la función de activación puede afectar tanto el aprendizaje como la estabilidad del modelo.
- **Tasa de Aprendizaje**: Determina la magnitud de los ajustes que se aplican a los pesos durante la retropropagación. Una tasa de aprendizaje muy alta puede hacer que el modelo diverja, mientras que una tasa demasiado baja puede hacer que el aprendizaje sea muy lento.
- **Tamaño del Lote (Batch Size)**: Define cuántos ejemplos de entrenamiento se usan para calcular el gradiente en cada paso. Un tamaño de lote grande reduce la varianza de los gradientes pero puede aumentar el costo computacional.
- **Número de Epochs**: Define cuántas veces se pasa por todo el conjunto de datos durante el entrenamiento. Este valor debe balancearse para evitar el sobreajuste.

#### Métodos para Ajustar Hiperparámetros

1. **Búsqueda en Grid (Grid Search)**
   - La **búsqueda en grid** es un método exhaustivo donde se define un conjunto de valores posibles para cada hiperparámetro y se prueban todas las combinaciones posibles. Aunque puede ser efectivo para problemas pequeños, es computacionalmente costoso y no escalable a redes complejas con múltiples hiperparámetros.

2. **Búsqueda Aleatoria (Randomized Search)**
   - En **búsqueda aleatoria**, se define un rango para cada hiperparámetro y luego se seleccionan valores al azar dentro de ese rango para probar. Este método suele ser más eficiente que la búsqueda en grid, ya que se enfoca en una muestra aleatoria de combinaciones en lugar de todas ellas, lo que reduce el costo computacional.

3. **Optimizadores Bayesianos**
   - **Optimización Bayesiana** es una técnica que trata de encontrar la mejor combinación de hiperparámetros mediante la construcción de un modelo probabilístico del espacio de búsqueda y seleccionando las combinaciones más prometedoras basadas en la evidencia observada. Esto es especialmente útil cuando el costo de evaluación es alto.
   - Herramientas como **Hyperopt** o **Optuna** implementan estos métodos para ajustar los hiperparámetros de modelos de aprendizaje profundo.

#### Estrategias para el Ajuste de Hiperparámetros

1. **Ajuste Progresivo**
   - En lugar de buscar todos los hiperparámetros a la vez, es común comenzar ajustando un hiperparámetro crítico mientras se mantienen los demás constantes. Luego se ajustan otros hiperparámetros basándose en los resultados del primer ajuste. Esto es útil para simplificar el proceso de búsqueda y minimizar el riesgo de combinaciones no efectivas.

2. **Escala Logarítmica**
   - Para ciertos hiperparámetros, como la **tasa de aprendizaje**, la escala lineal no es apropiada. En su lugar, se suele realizar una búsqueda en escala logarítmica, dado que pequeños cambios pueden tener un gran impacto en el rendimiento del modelo.

3. **Reducción del Conjunto de Datos para la Búsqueda**
   - Durante la búsqueda de hiperparámetros, entrenar la red completa en el conjunto total de datos puede ser costoso y lento. Utilizar un subconjunto del conjunto de datos para el ajuste preliminar ayuda a reducir significativamente el tiempo de búsqueda. Una vez que se encuentran buenos valores iniciales, se puede entrenar el modelo en el conjunto de datos completo.

#### Hiperparámetros a Ajustar Comúnmente

1. **Número de Capas Ocultas y Neuronas por Capa**: Ajustar el número de capas y el número de neuronas por capa es fundamental para encontrar el balance adecuado entre capacidad de aprendizaje y riesgo de sobreajuste.
2. **Tasa de Aprendizaje**: La tasa de aprendizaje es uno de los hiperparámetros más críticos. Un ajuste cuidadoso puede hacer la diferencia entre un modelo que converge rápidamente y otro que no lo hace.
3. **Batch Size**: Un tamaño de lote pequeño tiende a hacer que el entrenamiento sea más ruidoso, lo que puede ayudar a escapar de mínimos locales, mientras que un tamaño de lote grande tiende a ser más estable pero menos capaz de escapar de estos mínimos.




# Harvard Ordenar

## Definicion de modelo de 1 capa y de multiples capas

### **Primera Red Neuronal con una Sola Neurona**
En los ejemplos anteriores, creaste una red neuronal con una sola neurona, y la red aprendió a predecir la relación lineal entre los valores de **X** e **Y**. Usaste el siguiente código para definir esa red:

```python
my_layer = keras.layers.Dense(units=1, input_shape=[1])
model = tf.keras.Sequential([my_layer])
model.compile(optimizer='sgd', loss='mean_squared_error')

xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)
ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)

model.fit(xs, ys, epochs=500)
```

### **Inspección de Pesos y Sesgos**
Después de entrenar el modelo, puedes ver los pesos y sesgos aprendidos usando:

```python
print(my_layer.get_weights())
```

Este código te muestra dos arreglos:
- El primero contiene el peso aprendido (aproximadamente **2**).
- El segundo contiene el sesgo aprendido (aproximadamente **-1**).

### **Red Neuronal con Múltiples Capas**
A continuación, creamos una red neuronal más compleja con dos capas:
- La primera capa tiene **2 neuronas**.
- La segunda capa tiene **1 neurona**.

El código es el siguiente:

```python
my_layer_1 = keras.layers.Dense(units=2, input_shape=[1])
my_layer_2 = keras.layers.Dense(units=1)
model = tf.keras.Sequential([my_layer_1, my_layer_2])
model.compile(optimizer='sgd', loss='mean_squared_error')

xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)
ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)

model.fit(xs, ys, epochs=500)
```

### **Pesos y Sesgos en una Red con Múltiples Neuronas**
Cuando tienes más de una neurona, cada neurona en la segunda capa recibirá entradas de las dos neuronas de la primera capa. Por lo tanto, los pesos ahora se aplican a cada una de las entradas de la neurona. La ecuación sería:

**y = w1 * x1 + w2 * x2 + b**

Para ver los pesos y sesgos en cada capa:

```python
print(my_layer_1.get_weights())
print(my_layer_2.get_weights())
```

- **Capa 1**: Mostrará dos pesos y dos sesgos, uno para cada neurona de la capa.
- **Capa 2**: Mostrará dos pesos y un sesgo, aplicados a las dos neuronas de la capa anterior.

### **Cálculo Manual del Valor Predicho**
Puedes calcular manualmente la salida del modelo utilizando los pesos y sesgos obtenidos:

```python
value_to_predict = 10.0
layer1_w1 = (my_layer_1.get_weights()[0][0][0])
layer1_w2 = (my_layer_1.get_weights()[0][0][1])
layer1_b1 = (my_layer_1.get_weights()[1][0])
layer1_b2 = (my_layer_1.get_weights()[1][1])

layer2_w1 = (my_layer_2.get_weights()[0][0])
layer2_w2 = (my_layer_2.get_weights()[0][1])
layer2_b = (my_layer_2.get_weights()[1][0])

neuron1_output = (layer1_w1 * value_to_predict) + layer1_b1
neuron2_output = (layer1_w2 * value_to_predict) + layer1_b2

neuron3_output = (layer2_w1 * neuron1_output) + (layer2_w2 * neuron2_output) + layer2_b

print(neuron3_output)
```

Este código toma los pesos y sesgos aprendidos y calcula manualmente el valor de **Y** cuando **X = 10**. El resultado será cercano a **19**, como vimos anteriormente.

### **Aplicaciones de Redes Neuronales Más Complejas**
El proceso de usar múltiples capas y neuronas te permitirá aprender patrones más complejos en los datos. En próximos videos, explorarás cómo se pueden aplicar estas redes neuronales más complejas en tareas como la **visión por computadora** o el **reconocimiento de patrones en imágenes**. Además, más adelante en el curso, se verá cómo adaptar estos modelos en el contexto de **TinyML** para ejecutarlos en dispositivos con recursos limitados.



## **Regresión vs Clasificación**
Hasta ahora, trabajaste con **regresión**, que busca predecir un solo valor a partir de una o más entradas, como predecir **Y** a partir de **X** en una relación lineal. Ahora te adentras en la **clasificación**, donde el objetivo es etiquetar los datos, por ejemplo, identificar si una imagen contiene un perro o un gato.

### **Red Neuronal Multicapa**
Se construye una red neuronal con múltiples capas para procesar datos más complejos:
1. **Primera capa**: Tiene dos neuronas que procesan la entrada y aprenden pesos y sesgos.
2. **Segunda capa**: Toma las salidas de las neuronas de la primera capa y genera una salida que puede ser un valor continuo (regresión) o probabilidades de clasificación.




### **Predicción**
Después del entrenamiento, puedes usar `model.predict()` para predecir qué dígito es una imagen. El modelo devolverá un conjunto de probabilidades para cada clase, y la neurona con la probabilidad más alta indicará el dígito predicho.
